{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codice per la valutazione del progetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packege principali\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rimpiazzo NaN\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# ELimino Outliers Multivariati\n",
    "from collections import Counter\n",
    "from sklearn.cluster import DBSCAN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Spit Dati\n",
    "import sklearn.model_selection as model_select\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "# Salvataggio Classificatore\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo la classe che rimpiazza gli outliers che ci servira per pipeline e perch√® KNN non rimpiazza direttamente gli outliers\n",
    "# ma i nan quindi bisogna anche ricreare il metodo fit e il trasform\n",
    "\n",
    "class KNNReplacerIQR(KNNImputer):\n",
    "    \"\"\"Pipeline-compliant KNNReplacer, based on IQR.\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=2):\n",
    "        super().__init__(n_neighbors=n_neighbors)\n",
    "        self.lower_bound = None\n",
    "        self.upper_bound = None\n",
    "        self.imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        \"\"\"Computes IQR bound and fits the imputer on the data.\"\"\"\n",
    "        x = pd.DataFrame(x)\n",
    "        q1 = x.quantile(0.25)\n",
    "        q3 = x.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        self.lower_bound = q1 - (1.5* iqr)\n",
    "        self.upper_bound = q3 + (1.5* iqr)\n",
    "        self.imputer.fit(\n",
    "            x.where(~((x < self.lower_bound) | (x > self.upper_bound)), np.nan)\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        \"\"\"Detects outliers and replaces them with the imputer.\"\"\"\n",
    "        x = pd.DataFrame(x)\n",
    "        x.where(~((x < self.lower_bound) | (x > self.upper_bound)),\n",
    "                np.nan,\n",
    "                inplace=True)\n",
    "        return self.imputer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(cm, f1_score, title):\n",
    "    \"\"\"Displays confusion matrix with annotations.\"\"\"\n",
    "    # Create annotations label.\n",
    "    group_counts = [\"{0:0.0f}\\n\".format(value) for value in cm.flatten()]\n",
    "    group_percentages =\\\n",
    "        [\"{0:.2%}\".format(value) for value in cm.flatten() / np.sum(cm)]\n",
    "    box_labels =\\\n",
    "        [f\"{v1}{v2}\".strip() for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cm.shape[0], cm.shape[1])\n",
    "    # Show confusion matrix with heat map.\n",
    "    sns.heatmap(cm,\n",
    "                annot=box_labels,\n",
    "                fmt=\"\",\n",
    "                cmap=\"YlGnBu\",\n",
    "                cbar=False,\n",
    "                linewidths=1.0)\\\n",
    "        .set(title=title,\n",
    "             xlabel='Predicted class\\nF1 macro: %0.4f' % f1_score,\n",
    "             ylabel='Actual class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(classifier,imputer,cluster,smote, data_x, data_y, matrix_title='', show=True):\n",
    "    \"\"\"Preprocesses test set and evaluates classifiers.\"\"\"\n",
    "    data_x = imputer.transform(data_x)\n",
    "    X_imputer = pd.DataFrame(data_x)\n",
    "    Scanner = cluster.fit(X_imputer)\n",
    "    Outliers =X_imputer[Scanner.labels_==-1].index.values\n",
    "    x_final = pd.DataFrame(X_imputer).drop(index = Outliers)\n",
    "    y_final = data_y.drop(index = Outliers)\n",
    "    x_final, y_final = smote.fit_resample(x_final, y_final)\n",
    "    pred_y = classifier.predict(x_final)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_final, pred_y)\n",
    "    f1_score = metrics.f1_score(y_final, pred_y, average='macro')\n",
    "    print('\\nTest set F1 macro score: %0.4f .\\n' % f1_score)\n",
    "    if show:\n",
    "        show_confusion_matrix(confusion_matrix, f1_score, matrix_title)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "    # Load our classifier.\n",
    "    with open('imputer.sav', 'rb') as model_file:\n",
    "        imputer = pickle.load(model_file)\n",
    "    with open('cluster.sav', 'rb') as model_file:\n",
    "        cluster = pickle.load(model_file)\n",
    "    with open('smote.sav', 'rb') as model_file:\n",
    "        smote = pickle.load(model_file)\n",
    "    with open('best_classificatore.sav', 'rb') as model_file:\n",
    "        best_pipeline = pickle.load(model_file)\n",
    "\n",
    "    # Load test set.\n",
    "    testset_path = str(input(\"Enter test set file name: \"))\n",
    "    testset = pd.read_csv(testset_path)\n",
    "    print(\"TEST SET IMPORTED\")\n",
    "\n",
    "    # Separate features and labels.\n",
    "    x = testset.drop('Label', axis=1)\n",
    "    y = testset['Label']\n",
    "    \n",
    "    evaluate_classifier(best_pipeline,imputer,cluster,smote, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TEST SET IMPORTED\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "X has 20 features, but KNNImputer is expecting 23 features as input.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-00d0f0667a65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Start the script.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-a967b8f5b37a>\u001b[0m in \u001b[0;36mevaluation\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mevaluate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_pipeline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimputer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msmote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-d2af9ff53796>\u001b[0m in \u001b[0;36mevaluate_classifier\u001b[1;34m(classifier, imputer, cluster, smote, data_x, data_y, matrix_title, show)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimputer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msmote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix_title\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Preprocesses test set and evaluates classifiers.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdata_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mX_imputer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mScanner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_imputer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         X = self._validate_data(X, accept_sparse=False, dtype=FLOAT_DTYPES,\n\u001b[0m\u001b[0;32m    216\u001b[0m                                 \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                                 copy=self.copy, reset=False)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[1;31mValueError\u001b[0m: X has 20 features, but KNNImputer is expecting 23 features as input."
     ]
    }
   ],
   "source": [
    "# Start the script.\n",
    "if __name__ == '__main__':\n",
    "    evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "acd1c3ec51609f20a53a03da2acccc45a09f37cc8f609eca0fec515a53fdbe1a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}