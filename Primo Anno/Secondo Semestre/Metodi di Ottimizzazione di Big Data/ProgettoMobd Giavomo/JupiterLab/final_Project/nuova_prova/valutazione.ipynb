{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto Mobd\n",
    "    Authors: Giacomo Solfizi, Edoardo Rossi\n",
    "    Project: MOBD\n",
    "    Description: Script to generate and save best classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packege"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packege principali\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rimpiazzo NaN\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# ELimino Outliers Multivariati\n",
    "from collections import Counter\n",
    "from sklearn.cluster import DBSCAN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Spit Dati\n",
    "import sklearn.model_selection as model_select\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "\n",
    "# Salvataggio Classificatore\n",
    "import pickle\n",
    "# Path della best_classificator.\n",
    "best_classificator = 'best_path.sav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparo secondo pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo la classe che rimpiazza gli outliers che ci servira per pipeline e perch√® KNN non rimpiazza direttamente gli outliers\n",
    "# ma i nan quindi bisogna anche ricreare il metodo fit e il trasform\n",
    "\n",
    "class KNNReplacerIQR(KNNImputer):\n",
    "    \"\"\"Pipeline-compliant KNNReplacer, based on IQR.\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=2):\n",
    "        super().__init__(n_neighbors=n_neighbors)\n",
    "        self.lower_bound = None\n",
    "        self.upper_bound = None\n",
    "        self.imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        \"\"\"Computes IQR bound and fits the imputer on the data.\"\"\"\n",
    "        x = pd.DataFrame(x)\n",
    "        q1 = x.quantile(0.25)\n",
    "        q3 = x.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        self.lower_bound = q1 - (1.5* iqr)\n",
    "        self.upper_bound = q3 + (1.5* iqr)\n",
    "        self.imputer.fit(\n",
    "            x.where(~((x < self.lower_bound) | (x > self.upper_bound)), np.nan)\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        \"\"\"Detects outliers and replaces them with the imputer.\"\"\"\n",
    "        x = pd.DataFrame(x)\n",
    "        x.where(~((x < self.lower_bound) | (x > self.upper_bound)),\n",
    "                np.nan,\n",
    "                inplace=True)\n",
    "        return self.imputer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Principale\n",
    "Pipe_Knn_Bagging = Pipeline([   ('replacer', KNNReplacerIQR(n_neighbors = 2)),\n",
    "                                ('pre-process-QDA',PolynomialFeatures(degree=3)),\n",
    "                                ('scaler',StandardScaler()),\n",
    "                                ('decomposition',PCA(random_state = 42)),\n",
    "                                ('feature_selection', SelectFromModel(LinearSVC(C=0.01, penalty=\"l1\", dual=False))),\n",
    "                                ('classifier',BaggingClassifier(\n",
    "                                                 base_estimator=QDA(reg_param = 0.001,store_covariance =True,tol = 0.001),\n",
    "                                                 n_jobs = -1,\n",
    "                                                 random_state = 42))\n",
    "                            ])\n",
    "\n",
    "grid_Pipe_Knn_Bagging = {'replacer__n_neighbors': [2]}\n",
    "\n",
    "gs_Bagging_knn = model_select.GridSearchCV( Pipe_Knn_Bagging ,\n",
    "                                               param_grid =  grid_Pipe_Knn_Bagging,\n",
    "                                               scoring='f1_macro',\n",
    "                                               cv=5,\n",
    "                                               refit=True,\n",
    "                                               n_jobs=-1)\n",
    "# Lista pipeline\n",
    "grids = [gs_Bagging_knn]\n",
    "#Dizionario delle pipeline\n",
    "grid_dict_pipe = {0:'BEST PIPELINE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL OPTIMIZATIONS STARTED\n",
      "Currently trying model: BEST PIPELINE\n",
      "GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('replacer', KNNReplacerIQR()),\n",
      "                                       ('pre-process-QDA',\n",
      "                                        PolynomialFeatures(degree=3)),\n",
      "                                       ('scaler', StandardScaler()),\n",
      "                                       ('decomposition', PCA(random_state=42)),\n",
      "                                       ('feature_selection',\n",
      "                                        SelectFromModel(estimator=LinearSVC(C=0.01,\n",
      "                                                                            dual=False,\n",
      "                                                                            penalty='l1'))),\n",
      "                                       ('classifier',\n",
      "                                        BaggingClassifier(base_estimator=QuadraticDiscriminantAnalysis(reg_param=0.001,\n",
      "                                                                                                       store_covariance=True,\n",
      "                                                                                                       tol=0.001),\n",
      "                                                          n_jobs=-1,\n",
      "                                                          random_state=42))]),\n",
      "             n_jobs=-1, param_grid={'replacer__n_neighbors': [2]},\n",
      "             scoring='f1_macro')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f7b18283ce62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Perform grid search.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mpipe_gs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Dump detailed scores on a file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit the grid search objects and look for the best model.\n",
    "print(\"\\nMODEL OPTIMIZATIONS STARTED\")\n",
    "best_f1 = 0.0\n",
    "best_idx = 0\n",
    "best_pipe = None\n",
    "for idx, pipe_gs in enumerate(grids):\n",
    "    print('Currently trying model: %s' % grid_dict_pipe[idx])\n",
    "    print(pipe_gs)\n",
    "\n",
    "    # Perform grid search.\n",
    "    pipe_gs.fit(train_x, train_y[target])\n",
    "\n",
    "    # Dump detailed scores on a file.\n",
    "    results_file = open(grid_dict_pipe[idx] + '_results.txt', 'w')\n",
    "\n",
    "    # Print scores and update bests.\n",
    "    print(\"\\nGrid scores:\")\n",
    "    means = pipe_gs.cv_results_['mean_test_score']\n",
    "    stds = pipe_gs.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds,\n",
    "                                 pipe_gs.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "        results_file.write(\"%0.4f (+/-%0.03f) for %r\\n\"\n",
    "                           % (mean, std * 2, params))\n",
    "    print(\"\\nBest parameters:\")\n",
    "    print(pipe_gs.best_params_)\n",
    "    print(\"\\nBest score: %0.4f\" % pipe_gs.best_score_)\n",
    "    if pipe_gs.best_score_ > best_f1:\n",
    "        best_f1 = pipe_gs.best_score_\n",
    "        best_idx = idx\n",
    "        best_pipe = pipe_gs.best_estimator_\n",
    "    results_file.write(\"\\nBest parameters:\\n%r\\n\" % pipe_gs.best_params_)\n",
    "    results_file.write(\"\\nBest score: %0.4f\\n\" % pipe_gs.best_score_)\n",
    "\n",
    "    results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(cm, f1_score, title):\n",
    "    \"\"\"Displays confusion matrix with annotations.\"\"\"\n",
    "    # Create annotations label.\n",
    "    group_counts = [\"{0:0.0f}\\n\".format(value) for value in cm.flatten()]\n",
    "    group_percentages =\\\n",
    "        [\"{0:.2%}\".format(value) for value in cm.flatten() / np.sum(cm)]\n",
    "    box_labels =\\\n",
    "        [f\"{v1}{v2}\".strip() for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cm.shape[0], cm.shape[1])\n",
    "    # Show confusion matrix with heat map.\n",
    "    sns.heatmap(cm,\n",
    "                annot=box_labels,\n",
    "                fmt=\"\",\n",
    "                cmap=\"YlGnBu\",\n",
    "                cbar=False,\n",
    "                linewidths=1.0)\\\n",
    "        .set(title=title,\n",
    "             xlabel='Predicted class\\n\\nF1 macro: %0.4f' % f1_score,\n",
    "             ylabel='Actual class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(classifier, data_x, data_y, matrix_title='', show=True):\n",
    "    \"\"\"Preprocesses test set and evaluates classifiers.\"\"\"\n",
    "    pred_y = classifier.predict(data_x)\n",
    "    confusion_matrix = metrics.confusion_matrix(data_y, pred_y)\n",
    "    f1_score = metrics.f1_score(data_y, pred_y, average='macro')\n",
    "    if show:\n",
    "        show_confusion_matrix(confusion_matrix, f1_score, matrix_title)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(best_classificator, 'wb') as model_file:\n",
    "        pickle.dump(best_pipe, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Post-save) Dataset F1 macro: 0.9252\n"
     ]
    }
   ],
   "source": [
    "with open(best_classificator, 'rb') as model_file:\n",
    "        model = pickle.load(model_file)\n",
    "print('\\n(Post-save) Dataset F1 macro: %0.4f'\n",
    "          % evaluate_classifier(model,\n",
    "                                x,\n",
    "                                y[target],\n",
    "                                show=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
