{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione Progetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packege principali\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rimpiazzo NaN\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# ELimino Outliers Multivariati\n",
    "from collections import Counter\n",
    "from sklearn.cluster import DBSCAN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Spit Dati\n",
    "import sklearn.model_selection as model_select\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "\n",
    "# Salvataggio Classificatore\n",
    "import pickle\n",
    "# Path della best_classificator.\n",
    "target = 'CLASS'\n",
    "pipeline_path = 'best_pipeline2.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(cm, f1_score, title):\n",
    "    \"\"\"Displays confusion matrix with annotations.\"\"\"\n",
    "    # Create annotations label.\n",
    "    group_counts = [\"{0:0.0f}\\n\".format(value) for value in cm.flatten()]\n",
    "    group_percentages =\\\n",
    "        [\"{0:.2%}\".format(value) for value in cm.flatten() / np.sum(cm)]\n",
    "    box_labels =\\\n",
    "        [f\"{v1}{v2}\".strip() for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cm.shape[0], cm.shape[1])\n",
    "    # Show confusion matrix with heat map.\n",
    "    sns.heatmap(cm,\n",
    "                annot=box_labels,\n",
    "                fmt=\"\",\n",
    "                cmap=\"YlGnBu\",\n",
    "                cbar=False,\n",
    "                linewidths=1.0)\\\n",
    "        .set(title=title,\n",
    "             xlabel='Predicted class\\nF1 macro: %0.4f' % f1_score,\n",
    "             ylabel='Actual class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "    \"\"\"Evaluates our classifier on the test set.\"\"\"\n",
    "    # Load our classifier.\n",
    "    with open('best_pipeline.sav', 'rb') as model_file:\n",
    "        best_pipeline = pickle.load(model_file)\n",
    "\n",
    "    # Load test set.\n",
    "    testset = pd.read_csv('training_set.csv')\n",
    "    print(\"TEST SET IMPORTED\")\n",
    "\n",
    "    # Separate features and labels.\n",
    "    x = testset.drop('CLASS', axis=1)\n",
    "    y = testset['CLASS']\n",
    "\n",
    "    evaluate_classifier(best_pipeline, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(classifier, data_x, data_y, matrix_title='', show=True):\n",
    "    \"\"\"Preprocesses test set and evaluates classifiers.\"\"\"\n",
    "    pred_y = classifier.predict(data_x)\n",
    "    confusion_matrix = metrics.confusion_matrix(data_y, pred_y)\n",
    "    f1_score = metrics.f1_score(data_y, pred_y, average='macro')\n",
    "    print('\\nTest set F1 macro score: %0.4f .\\n' % f1_score)\n",
    "    if show:\n",
    "        show_confusion_matrix(confusion_matrix, f1_score, matrix_title)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo la classe che rimpiazza gli outliers che ci servira per pipeline e perch√® KNN non rimpiazza direttamente gli outliers\n",
    "# ma i nan quindi bisogna anche ricreare il metodo fit e il trasform\n",
    "\n",
    "class KNNReplacerIQR(KNNImputer):\n",
    "    \"\"\"Pipeline-compliant KNNReplacer, based on IQR.\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=2):\n",
    "        super().__init__(n_neighbors=n_neighbors)\n",
    "        self.lower_bound = None\n",
    "        self.upper_bound = None\n",
    "        self.imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        \"\"\"Computes IQR bound and fits the imputer on the data.\"\"\"\n",
    "        x = pd.DataFrame(x)\n",
    "        q1 = x.quantile(0.25)\n",
    "        q3 = x.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        self.lower_bound = q1 - (1.5* iqr)\n",
    "        self.upper_bound = q3 + (1.5* iqr)\n",
    "        self.imputer.fit(\n",
    "            x.where(~((x < self.lower_bound) | (x > self.upper_bound)), np.nan)\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        \"\"\"Detects outliers and replaces them with the imputer.\"\"\"\n",
    "        x = pd.DataFrame(x)\n",
    "        x.where(~((x < self.lower_bound) | (x > self.upper_bound)),\n",
    "                np.nan,\n",
    "                inplace=True)\n",
    "        return self.imputer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Performs analysis and determines the best model for this problem.\"\"\"\n",
    "    # Read dataset.\n",
    "    dataset_path = 'training_set.csv'\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "    print(\"DATASET IMPORTED\")\n",
    "    print('\\nDataset shape:', dataset.shape)\n",
    "    print(dataset.describe())\n",
    "    print('\\nLast dataset entries:', dataset.tail())\n",
    "\n",
    "    # Separate features and target labels.\n",
    "    x = dataset.drop(target, axis=1)\n",
    "    y = dataset[[target]]\n",
    "    features_list = x.columns.values.tolist()\n",
    "    \n",
    "    # Elimino nan iniziali\n",
    "    imputer = KNNImputer(n_neighbors=2)\n",
    "    dati_imputati_0 = imputer.fit(x)\n",
    "    dati_imputati_1 = dati_imputati_0.transform(x)\n",
    "    # Dataset senza NaN\n",
    "    X_imputer = pd.DataFrame(dati_imputati_1)\n",
    "\n",
    "    # Faccio clustering per eliminare gli Outliers Multivariati\n",
    "    Scanner = DBSCAN(eps=6.6, min_samples=10,n_jobs = -1).fit(X_imputer)\n",
    "    Outliers = X_imputer[Scanner.labels_==-1].index.values\n",
    "    x_final = pd.DataFrame(X_imputer).drop(index = Outliers)\n",
    "    y_final = y.drop(index = Outliers)\n",
    "\n",
    "    # Sovracampiono il dataset con valori simili\n",
    "    oversample = SMOTE()\n",
    "    x_final, y_final = oversample.fit_resample(x_final, y_final)\n",
    "\n",
    "    # Split dataset in training set and test set.\n",
    "    train_x, test_x, train_y, test_y = \\\n",
    "        model_select.train_test_split(x_final, y_final,\n",
    "                                      test_size=0.2,\n",
    "                                      random_state=42,\n",
    "                                      stratify=y_final)\n",
    "    print('\\nTraining set shape:', train_x.shape, train_y.shape)\n",
    "    print('Test set shape:', test_x.shape, test_y.shape)\n",
    "\n",
    "    # Display data proportions after splitting.\n",
    "    #show_classes_proportions(y, 'Dataset classes proportions')\n",
    "    #show_classes_proportions(train_y, 'Training set classes proportions')\n",
    "    #show_classes_proportions(test_y, 'Test set classes proportions')\n",
    "\n",
    "    # Define pipelines for preprocessing.\n",
    "    Pipe_Knn_Bagging = Pipeline([   ('replacer', KNNReplacerIQR(n_neighbors = 2)),\n",
    "                                    ('pre-process-QDA',PolynomialFeatures(degree=3)),\n",
    "                                    ('scaler',StandardScaler()),\n",
    "                                    ('decomposition',PCA(random_state = 42)),\n",
    "                                    ('feature_selection', SelectFromModel(LinearSVC(C=0.01, penalty=\"l1\", dual=False))),\n",
    "                                    ('classifier',BaggingClassifier(\n",
    "                                                 base_estimator=QDA(reg_param = 0.001,store_covariance =True,tol = 0.001),\n",
    "                                                 n_jobs = -1,\n",
    "                                                 random_state = 42))\n",
    "                                ])\n",
    "\n",
    "    # Set the parameters grids.\n",
    "    grid_Pipe_Knn_Bagging = {'replacer__n_neighbors': [2]}\n",
    "\n",
    "\n",
    "    # Define grid searches for each pipeline.\n",
    "    gs_Bagging_knn = model_select.GridSearchCV( Pipe_Knn_Bagging ,\n",
    "                                               param_grid =  grid_Pipe_Knn_Bagging,\n",
    "                                               scoring='f1_macro',\n",
    "                                               cv=5,\n",
    "                                               refit=True,\n",
    "                                               n_jobs=-1)\n",
    "\n",
    "    # Lista pipeline\n",
    "    grids = [gs_Bagging_knn]\n",
    "    #Dizionario delle pipeline\n",
    "    grid_dict_pipe = {0:'BEST PIPELINE'}\n",
    "\n",
    "    # Fit the grid search objects and look for the best model.\n",
    "    print(\"\\nMODEL OPTIMIZATIONS STARTED\")\n",
    "    best_f1 = 0.0\n",
    "    best_idx = 0\n",
    "    best_pipe = None\n",
    "    for idx, pipe_gs in enumerate(grids):\n",
    "        print('Currently trying model: %s' % grid_dict_pipe[idx])\n",
    "\n",
    "        # Perform grid search.\n",
    "        pipe_gs.fit(train_x, train_y[target])\n",
    "\n",
    "        # Dump detailed scores on a file.\n",
    "        results_file = open(grid_dict_pipe[idx] + '_results.txt', 'w')\n",
    "\n",
    "        # Print scores and update bests.\n",
    "        print(\"\\nGrid scores:\")\n",
    "        means = pipe_gs.cv_results_['mean_test_score']\n",
    "        stds = pipe_gs.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds,\n",
    "                                     pipe_gs.cv_results_['params']):\n",
    "            print(\"%0.4f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "            results_file.write(\"%0.4f (+/-%0.03f) for %r\\n\"\n",
    "                               % (mean, std * 2, params))\n",
    "        print(\"\\nBest parameters:\")\n",
    "        print(pipe_gs.best_params_)\n",
    "        print(\"\\nBest score: %0.4f\" % pipe_gs.best_score_)\n",
    "        if pipe_gs.best_score_ > best_f1:\n",
    "            best_f1 = pipe_gs.best_score_\n",
    "            best_idx = idx\n",
    "            best_pipe = pipe_gs.best_estimator_\n",
    "        results_file.write(\"\\nBest parameters:\\n%r\\n\" % pipe_gs.best_params_)\n",
    "        results_file.write(\"\\nBest score: %0.4f\\n\" % pipe_gs.best_score_)\n",
    "\n",
    "        results_file.close()\n",
    "\n",
    "    print('\\nPipeline with best training set F1 macro score: %s'\n",
    "          % grid_dict_pipe[best_idx])\n",
    "\n",
    "    # Show information and plots about best preprocessing pipeline.\n",
    "    #data_preparation_info(train_x, features_list, best_pipe)\n",
    "\n",
    "    # Evaluates the pipeline on the test set.\n",
    "    \n",
    "    # Serialize and dump the best model.\n",
    "\n",
    "    with open(pipeline_path, 'wb') as model_file:\n",
    "        pickle.dump(best_pipe, model_file)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET IMPORTED\n",
      "\n",
      "Dataset shape: (8000, 21)\n",
      "                F1           F2           F3           F4           F5  \\\n",
      "count  7994.000000  7994.000000  7999.000000  7999.000000  7996.000000   \n",
      "mean     -0.013077    -0.261413    -0.356239    -0.107298    -0.505798   \n",
      "std       1.006235     1.852793     1.794600     3.038362     1.818965   \n",
      "min      -4.181155    -6.980290    -7.563245   -13.133565    -9.011808   \n",
      "25%      -0.698506    -1.441144    -1.564076    -1.854212    -1.735180   \n",
      "50%      -0.028194    -0.261095    -0.375098    -0.022912    -0.511772   \n",
      "75%       0.666096     0.944857     0.824168     1.757135     0.691109   \n",
      "max       3.774161     7.155359     6.774458    10.975842     6.420768   \n",
      "\n",
      "                F6           F7           F8           F9          F10  ...  \\\n",
      "count  7994.000000  7996.000000  7991.000000  7994.000000  7994.000000  ...   \n",
      "mean      0.170845    -0.142636     0.135534    -0.004581     0.017338  ...   \n",
      "std       3.802454     1.901893     1.846124     1.005507     1.005563  ...   \n",
      "min     -15.887455    -7.934826    -8.608330    -3.472781    -3.697495  ...   \n",
      "25%      -2.187097    -1.412976    -1.099665    -0.684807    -0.672081  ...   \n",
      "50%       0.086112    -0.117316     0.144827     0.004093     0.029326  ...   \n",
      "75%       2.445748     1.121002     1.411072     0.664729     0.704140  ...   \n",
      "max      17.343261     7.222491     6.664533     3.811616     3.391975  ...   \n",
      "\n",
      "               F12          F13          F14          F15          F16  \\\n",
      "count  7994.000000  7997.000000  7990.000000  7998.000000  7994.000000   \n",
      "mean      0.000023    -0.051170    -0.011521     0.032990    -0.294768   \n",
      "std       1.960223     1.936503     2.069112     2.013245     1.970592   \n",
      "min      -7.212589    -8.133189    -7.823196    -8.969136    -7.037129   \n",
      "25%      -1.325372    -1.337362    -1.383780    -1.298123    -1.612006   \n",
      "50%      -0.037385    -0.067058    -0.036499    -0.033036    -0.308933   \n",
      "75%       1.283942     1.245172     1.365177     1.314362     1.021518   \n",
      "max       7.181241     8.819808     7.970802     9.235606     9.415568   \n",
      "\n",
      "               F17          F18          F19          F20        CLASS  \n",
      "count  7996.000000  7993.000000  7995.000000  7997.000000  8000.000000  \n",
      "mean     -0.026807    -0.293875     0.001092    -0.355555     1.463375  \n",
      "std       0.978187     1.971526     0.996603     1.794666     1.231198  \n",
      "min      -3.621038    -7.037129    -4.013615    -7.563245     0.000000  \n",
      "25%      -0.689233    -1.612119    -0.669021    -1.563262     0.000000  \n",
      "50%      -0.035249    -0.308409    -0.004635    -0.373514     2.000000  \n",
      "75%       0.634916     1.022557     0.676510     0.825741     3.000000  \n",
      "max       3.951352     9.415568     3.606960     6.774458     3.000000  \n",
      "\n",
      "[8 rows x 21 columns]\n",
      "\n",
      "Last dataset entries:             F1        F2        F3        F4        F5        F6        F7  \\\n",
      "7995  0.405098  0.592920  2.441859 -1.134919  2.248627  2.509097 -0.227617   \n",
      "7996 -0.404388  1.813804 -2.483380  2.093664  0.139423  2.617027  0.489677   \n",
      "7997  0.233546 -1.003142 -2.121826  1.581558  1.152723 -0.987152  0.337969   \n",
      "7998  1.120382  0.194409 -0.672968  0.005154  2.290353  4.112554  0.720367   \n",
      "7999  0.994641 -1.185386 -3.610239  0.185566 -1.534623  3.021333 -0.721372   \n",
      "\n",
      "            F8        F9       F10  ...       F12       F13       F14  \\\n",
      "7995  0.275321 -0.274926 -0.595862  ... -0.169544 -0.255823  2.695956   \n",
      "7996  1.387914 -0.363073  0.030530  ...  0.124103  0.056482 -0.333988   \n",
      "7997 -4.654229 -0.417682 -1.260857  ...  2.469214  2.782867  0.888288   \n",
      "7998  0.563533 -1.009534 -1.551473  ...  0.607569  3.102179  4.237942   \n",
      "7999 -3.250708 -0.034000 -0.102102  ... -3.273256  3.908861  0.809098   \n",
      "\n",
      "           F15       F16       F17       F18       F19       F20  CLASS  \n",
      "7995 -2.220396 -2.432903 -0.131110 -2.432903 -0.479939  2.441859      1  \n",
      "7996 -1.204211 -0.224673  1.521622 -0.224673 -1.096852 -2.483380      2  \n",
      "7997  0.335607 -2.248307 -1.386542 -2.248307  0.934043 -2.121826      0  \n",
      "7998 -0.710731 -0.359420 -1.500903 -0.359420 -0.658633 -0.672968      1  \n",
      "7999  2.970013 -2.104526 -0.419366 -2.104526  1.655029 -3.610239      3  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Training set shape: (8502, 20) (8502, 1)\n",
      "Test set shape: (2126, 20) (2126, 1)\n",
      "\n",
      "MODEL OPTIMIZATIONS STARTED\n",
      "Currently trying model: BEST PIPELINE\n",
      "\n",
      "Grid scores:\n",
      "0.8884 (+/-0.004) for {'replacer__n_neighbors': 2}\n",
      "\n",
      "Best parameters:\n",
      "{'replacer__n_neighbors': 2}\n",
      "\n",
      "Best score: 0.8884\n",
      "\n",
      "Pipeline with best training set F1 macro score: BEST PIPELINE\n"
     ]
    }
   ],
   "source": [
    "# Start the script.\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-95d682f63204>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m print('\\n(Post-save) Dataset F1 macro: %0.4f'\n\u001b[0;32m      5\u001b[0m      % evaluate_classifier(model,\n\u001b[1;32m----> 6\u001b[1;33m                            \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                            \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                            show=False))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    " # Reload best model and check if the save went well.\n",
    "with open(pipeline_path, 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "print('\\n(Post-save) Dataset F1 macro: %0.4f'\n",
    "      % evaluate_classifier(model,\n",
    "                            x,\n",
    "                            y[target],\n",
    "                            show=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-5e6e498982b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m print('\\nTest set F1 macro: %0.4f'\n\u001b[1;32m----> 2\u001b[1;33m           % evaluate_classifier(best_pipe,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                 \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                 \u001b[0mtest_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 'Test Set Confusion matrix'))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_pipe' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\nTest set F1 macro: %0.4f'\n",
    "          % evaluate_classifier(best_pipe,\n",
    "                                test_x,\n",
    "                                test_y[target],\n",
    "                                'Test Set Confusion matrix'))\n",
    "\n",
    "# Refit the best pipeline on the whole dataset.\n",
    "print(\"\\nRE-FITTING BEST PIPELINE ON WHOLE DATASET\")\n",
    "best_pipe = best_pipe.fit(x, y[target])\n",
    "print('\\n(Pre-save) Dataset F1 macro: %0.4f'\n",
    "      % evaluate_classifier(best_pipe,\n",
    "                            x,\n",
    "                            y[target],\n",
    "                            'Dataset Confusion matrix'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
