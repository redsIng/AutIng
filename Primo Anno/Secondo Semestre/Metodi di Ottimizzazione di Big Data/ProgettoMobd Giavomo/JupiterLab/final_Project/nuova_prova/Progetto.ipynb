{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROGETTO MOBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packege"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "# Rimpiazzo NaN\n",
    "from sklearn.impute import KNNImputer\n",
    "# ELimino Outliers Multivariati\n",
    "from collections import Counter\n",
    "from sklearn.cluster import DBSCAN\n",
    "# Spit Dati\n",
    "import sklearn.model_selection as model_select\n",
    "# Robba per Pipeline\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Features selections\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0    -0.555694 -0.848258  0.132180 -4.061760  1.661394  2.219988  0.360537   \n",
       "1     0.293193 -2.628978 -1.154407  0.538828 -0.169857  3.487574  0.443397   \n",
       "2    -2.078656 -0.834492  1.241461  1.010122 -1.638526  0.247378 -1.887390   \n",
       "3    -1.294256 -2.804065 -1.335397 -1.351379 -0.327137  1.199219  0.262458   \n",
       "4    -0.525611  0.024948  1.609361 -0.248425  1.533188  0.580862  0.049771   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7995  0.405098  0.592920  2.441859 -1.134919  2.248627  2.509097 -0.227617   \n",
       "7996 -0.404388  1.813804 -2.483380  2.093664  0.139423  2.617027  0.489677   \n",
       "7997  0.233546 -1.003142 -2.121826  1.581558  1.152723 -0.987152  0.337969   \n",
       "7998  1.120382  0.194409 -0.672968  0.005154  2.290353  4.112554  0.720367   \n",
       "7999  0.994641 -1.185386 -3.610239  0.185566 -1.534623  3.021333 -0.721372   \n",
       "\n",
       "            F8        F9       F10  ...       F12       F13       F14  \\\n",
       "0     2.537116 -0.613588  2.078144  ... -2.492234  0.808907 -1.078887   \n",
       "1    -0.006410 -0.125778  1.223669  ... -1.723842  1.772836  0.467387   \n",
       "2    -1.331368 -2.159086  0.002788  ... -1.686278 -1.047410 -1.133299   \n",
       "3     0.825120 -0.638883  1.660732  ...  4.437570 -0.093413  2.637345   \n",
       "4    -0.430270 -0.714264 -0.186867  ...  0.404803 -0.733368  1.288384   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7995  0.275321 -0.274926 -0.595862  ... -0.169544 -0.255823  2.695956   \n",
       "7996  1.387914 -0.363073  0.030530  ...  0.124103  0.056482 -0.333988   \n",
       "7997 -4.654229 -0.417682 -1.260857  ...  2.469214  2.782867  0.888288   \n",
       "7998  0.563533 -1.009534 -1.551473  ...  0.607569  3.102179  4.237942   \n",
       "7999 -3.250708 -0.034000 -0.102102  ... -3.273256  3.908861  0.809098   \n",
       "\n",
       "           F15       F16       F17       F18       F19       F20  CLASS  \n",
       "0     3.438161  2.372122  1.899934  2.372122  2.219416  0.132180      2  \n",
       "1    -1.501851 -3.599221 -0.968531 -3.599221  1.127776 -1.154407      0  \n",
       "2    -1.953928 -1.149684  1.111692 -1.149684  0.134184  1.241461      1  \n",
       "3    -2.415704 -4.679002  0.511314 -4.679002  0.805571 -1.335397      0  \n",
       "4    -1.646543 -1.020989  0.658584 -1.020989  1.412792  1.609361      1  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "7995 -2.220396 -2.432903 -0.131110 -2.432903 -0.479939  2.441859      1  \n",
       "7996 -1.204211 -0.224673  1.521622 -0.224673 -1.096852 -2.483380      2  \n",
       "7997  0.335607 -2.248307 -1.386542 -2.248307  0.934043 -2.121826      0  \n",
       "7998 -0.710731 -0.359420 -1.500903 -0.359420 -0.658633 -0.672968      1  \n",
       "7999  2.970013 -2.104526 -0.419366 -2.104526  1.655029 -3.610239      3  \n",
       "\n",
       "[8000 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>F1</th>\n      <th>F2</th>\n      <th>F3</th>\n      <th>F4</th>\n      <th>F5</th>\n      <th>F6</th>\n      <th>F7</th>\n      <th>F8</th>\n      <th>F9</th>\n      <th>F10</th>\n      <th>...</th>\n      <th>F12</th>\n      <th>F13</th>\n      <th>F14</th>\n      <th>F15</th>\n      <th>F16</th>\n      <th>F17</th>\n      <th>F18</th>\n      <th>F19</th>\n      <th>F20</th>\n      <th>CLASS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.555694</td>\n      <td>-0.848258</td>\n      <td>0.132180</td>\n      <td>-4.061760</td>\n      <td>1.661394</td>\n      <td>2.219988</td>\n      <td>0.360537</td>\n      <td>2.537116</td>\n      <td>-0.613588</td>\n      <td>2.078144</td>\n      <td>...</td>\n      <td>-2.492234</td>\n      <td>0.808907</td>\n      <td>-1.078887</td>\n      <td>3.438161</td>\n      <td>2.372122</td>\n      <td>1.899934</td>\n      <td>2.372122</td>\n      <td>2.219416</td>\n      <td>0.132180</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.293193</td>\n      <td>-2.628978</td>\n      <td>-1.154407</td>\n      <td>0.538828</td>\n      <td>-0.169857</td>\n      <td>3.487574</td>\n      <td>0.443397</td>\n      <td>-0.006410</td>\n      <td>-0.125778</td>\n      <td>1.223669</td>\n      <td>...</td>\n      <td>-1.723842</td>\n      <td>1.772836</td>\n      <td>0.467387</td>\n      <td>-1.501851</td>\n      <td>-3.599221</td>\n      <td>-0.968531</td>\n      <td>-3.599221</td>\n      <td>1.127776</td>\n      <td>-1.154407</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-2.078656</td>\n      <td>-0.834492</td>\n      <td>1.241461</td>\n      <td>1.010122</td>\n      <td>-1.638526</td>\n      <td>0.247378</td>\n      <td>-1.887390</td>\n      <td>-1.331368</td>\n      <td>-2.159086</td>\n      <td>0.002788</td>\n      <td>...</td>\n      <td>-1.686278</td>\n      <td>-1.047410</td>\n      <td>-1.133299</td>\n      <td>-1.953928</td>\n      <td>-1.149684</td>\n      <td>1.111692</td>\n      <td>-1.149684</td>\n      <td>0.134184</td>\n      <td>1.241461</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.294256</td>\n      <td>-2.804065</td>\n      <td>-1.335397</td>\n      <td>-1.351379</td>\n      <td>-0.327137</td>\n      <td>1.199219</td>\n      <td>0.262458</td>\n      <td>0.825120</td>\n      <td>-0.638883</td>\n      <td>1.660732</td>\n      <td>...</td>\n      <td>4.437570</td>\n      <td>-0.093413</td>\n      <td>2.637345</td>\n      <td>-2.415704</td>\n      <td>-4.679002</td>\n      <td>0.511314</td>\n      <td>-4.679002</td>\n      <td>0.805571</td>\n      <td>-1.335397</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.525611</td>\n      <td>0.024948</td>\n      <td>1.609361</td>\n      <td>-0.248425</td>\n      <td>1.533188</td>\n      <td>0.580862</td>\n      <td>0.049771</td>\n      <td>-0.430270</td>\n      <td>-0.714264</td>\n      <td>-0.186867</td>\n      <td>...</td>\n      <td>0.404803</td>\n      <td>-0.733368</td>\n      <td>1.288384</td>\n      <td>-1.646543</td>\n      <td>-1.020989</td>\n      <td>0.658584</td>\n      <td>-1.020989</td>\n      <td>1.412792</td>\n      <td>1.609361</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7995</th>\n      <td>0.405098</td>\n      <td>0.592920</td>\n      <td>2.441859</td>\n      <td>-1.134919</td>\n      <td>2.248627</td>\n      <td>2.509097</td>\n      <td>-0.227617</td>\n      <td>0.275321</td>\n      <td>-0.274926</td>\n      <td>-0.595862</td>\n      <td>...</td>\n      <td>-0.169544</td>\n      <td>-0.255823</td>\n      <td>2.695956</td>\n      <td>-2.220396</td>\n      <td>-2.432903</td>\n      <td>-0.131110</td>\n      <td>-2.432903</td>\n      <td>-0.479939</td>\n      <td>2.441859</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7996</th>\n      <td>-0.404388</td>\n      <td>1.813804</td>\n      <td>-2.483380</td>\n      <td>2.093664</td>\n      <td>0.139423</td>\n      <td>2.617027</td>\n      <td>0.489677</td>\n      <td>1.387914</td>\n      <td>-0.363073</td>\n      <td>0.030530</td>\n      <td>...</td>\n      <td>0.124103</td>\n      <td>0.056482</td>\n      <td>-0.333988</td>\n      <td>-1.204211</td>\n      <td>-0.224673</td>\n      <td>1.521622</td>\n      <td>-0.224673</td>\n      <td>-1.096852</td>\n      <td>-2.483380</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7997</th>\n      <td>0.233546</td>\n      <td>-1.003142</td>\n      <td>-2.121826</td>\n      <td>1.581558</td>\n      <td>1.152723</td>\n      <td>-0.987152</td>\n      <td>0.337969</td>\n      <td>-4.654229</td>\n      <td>-0.417682</td>\n      <td>-1.260857</td>\n      <td>...</td>\n      <td>2.469214</td>\n      <td>2.782867</td>\n      <td>0.888288</td>\n      <td>0.335607</td>\n      <td>-2.248307</td>\n      <td>-1.386542</td>\n      <td>-2.248307</td>\n      <td>0.934043</td>\n      <td>-2.121826</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7998</th>\n      <td>1.120382</td>\n      <td>0.194409</td>\n      <td>-0.672968</td>\n      <td>0.005154</td>\n      <td>2.290353</td>\n      <td>4.112554</td>\n      <td>0.720367</td>\n      <td>0.563533</td>\n      <td>-1.009534</td>\n      <td>-1.551473</td>\n      <td>...</td>\n      <td>0.607569</td>\n      <td>3.102179</td>\n      <td>4.237942</td>\n      <td>-0.710731</td>\n      <td>-0.359420</td>\n      <td>-1.500903</td>\n      <td>-0.359420</td>\n      <td>-0.658633</td>\n      <td>-0.672968</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7999</th>\n      <td>0.994641</td>\n      <td>-1.185386</td>\n      <td>-3.610239</td>\n      <td>0.185566</td>\n      <td>-1.534623</td>\n      <td>3.021333</td>\n      <td>-0.721372</td>\n      <td>-3.250708</td>\n      <td>-0.034000</td>\n      <td>-0.102102</td>\n      <td>...</td>\n      <td>-3.273256</td>\n      <td>3.908861</td>\n      <td>0.809098</td>\n      <td>2.970013</td>\n      <td>-2.104526</td>\n      <td>-0.419366</td>\n      <td>-2.104526</td>\n      <td>1.655029</td>\n      <td>-3.610239</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>8000 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#Importo dati\n",
    "dataset = pd.read_csv('training_set1.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Variabili Indipendenti X:\n             F1        F2        F3        F4        F5        F6        F7  \\\n0    -0.555694 -0.848258  0.132180 -4.061760  1.661394  2.219988  0.360537   \n1     0.293193 -2.628978 -1.154407  0.538828 -0.169857  3.487574  0.443397   \n2    -2.078656 -0.834492  1.241461  1.010122 -1.638526  0.247378 -1.887390   \n3    -1.294256 -2.804065 -1.335397 -1.351379 -0.327137  1.199219  0.262458   \n4    -0.525611  0.024948  1.609361 -0.248425  1.533188  0.580862  0.049771   \n...        ...       ...       ...       ...       ...       ...       ...   \n7995  0.405098  0.592920  2.441859 -1.134919  2.248627  2.509097 -0.227617   \n7996 -0.404388  1.813804 -2.483380  2.093664  0.139423  2.617027  0.489677   \n7997  0.233546 -1.003142 -2.121826  1.581558  1.152723 -0.987152  0.337969   \n7998  1.120382  0.194409 -0.672968  0.005154  2.290353  4.112554  0.720367   \n7999  0.994641 -1.185386 -3.610239  0.185566 -1.534623  3.021333 -0.721372   \n\n            F8        F9       F10       F11       F12       F13       F14  \\\n0     2.537116 -0.613588  2.078144  0.128270 -2.492234  0.808907 -1.078887   \n1    -0.006410 -0.125778  1.223669  0.239508 -1.723842  1.772836  0.467387   \n2    -1.331368 -2.159086  0.002788 -0.397360 -1.686278 -1.047410 -1.133299   \n3     0.825120 -0.638883  1.660732 -2.045188  4.437570 -0.093413  2.637345   \n4    -0.430270 -0.714264 -0.186867  0.572004  0.404803 -0.733368  1.288384   \n...        ...       ...       ...       ...       ...       ...       ...   \n7995  0.275321 -0.274926 -0.595862  1.379110 -0.169544 -0.255823  2.695956   \n7996  1.387914 -0.363073  0.030530  0.962490  0.124103  0.056482 -0.333988   \n7997 -4.654229 -0.417682 -1.260857  4.472366  2.469214  2.782867  0.888288   \n7998  0.563533 -1.009534 -1.551473 -0.697174  0.607569  3.102179  4.237942   \n7999 -3.250708 -0.034000 -0.102102  6.857379 -3.273256  3.908861  0.809098   \n\n           F15       F16       F17       F18       F19       F20  \n0     3.438161  2.372122  1.899934  2.372122  2.219416  0.132180  \n1    -1.501851 -3.599221 -0.968531 -3.599221  1.127776 -1.154407  \n2    -1.953928 -1.149684  1.111692 -1.149684  0.134184  1.241461  \n3    -2.415704 -4.679002  0.511314 -4.679002  0.805571 -1.335397  \n4    -1.646543 -1.020989  0.658584 -1.020989  1.412792  1.609361  \n...        ...       ...       ...       ...       ...       ...  \n7995 -2.220396 -2.432903 -0.131110 -2.432903 -0.479939  2.441859  \n7996 -1.204211 -0.224673  1.521622 -0.224673 -1.096852 -2.483380  \n7997  0.335607 -2.248307 -1.386542 -2.248307  0.934043 -2.121826  \n7998 -0.710731 -0.359420 -1.500903 -0.359420 -0.658633 -0.672968  \n7999  2.970013 -2.104526 -0.419366 -2.104526  1.655029 -3.610239  \n\n[8000 rows x 20 columns]\n\nVariabili Dipendenti Y:\n       CLASS\n0         2\n1         0\n2         1\n3         0\n4         1\n...     ...\n7995      1\n7996      2\n7997      0\n7998      1\n7999      3\n\n[8000 rows x 1 columns]\nLista Features:\n ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20']\n"
     ]
    }
   ],
   "source": [
    "# Separiamo i valori dalle features dalle classi\n",
    "target = 'CLASS'\n",
    "x = dataset.drop(target, axis=1)\n",
    "print('Variabili Indipendenti X:\\n', x)\n",
    "# Separiamo i valori delle Classi dalle features\n",
    "y = dataset[[target]]\n",
    "print('\\nVariabili Dipendenti Y:\\n', y)\n",
    "# Lista delle features\n",
    "features_list = x.columns.values.tolist()\n",
    "print('Lista Features:\\n', features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rimpiazzo subito i NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione base per il calcolo dei NaN\n",
    "def get_na_count(dataset):\n",
    "    # per ogni elemento (i,j) del dataset, isna() restituisce \n",
    "    # TRUE/FALSE se il valore corrispondente è mancante/presente\n",
    "    boolean_mask = dataset.isna()\n",
    "    # contiamo il numero di TRUE per ogni attributo sul dataset\n",
    "    return boolean_mask.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1      6\nF2      6\nF3      1\nF4      1\nF5      4\nF6      6\nF7      4\nF8      9\nF9      6\nF10     6\nF11     5\nF12     6\nF13     3\nF14    10\nF15     2\nF16     6\nF17     4\nF18     7\nF19     5\nF20     3\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "summary_nan_1 = get_na_count(x)\n",
    "print(summary_nan_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0     0\n1     0\n2     0\n3     0\n4     0\n5     0\n6     0\n7     0\n8     0\n9     0\n10    0\n11    0\n12    0\n13    0\n14    0\n15    0\n16    0\n17    0\n18    0\n19    0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=2)\n",
    "dati_imputati = imputer.fit(x).transform(x)\n",
    "summary_nan_2 = get_na_count(pd.DataFrame(dati_imputati))\n",
    "print(summary_nan_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset senza NaN\n",
    "X_imputer = pd.DataFrame(dati_imputati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean     -0.012763    -0.261770    -0.355985    -0.107223    -0.505726   \n",
       "std       1.006266     1.852754     1.794632     3.038180     1.818525   \n",
       "min      -4.181155    -6.980290    -7.563245   -13.133565    -9.011808   \n",
       "25%      -0.697289    -1.441506    -1.563905    -1.853387    -1.734750   \n",
       "50%      -0.028030    -0.261043    -0.374563    -0.021507    -0.511772   \n",
       "75%       0.665953     0.944838     0.824602     1.757076     0.688574   \n",
       "max       3.774161     7.155359     6.774458    10.975842     6.420768   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      0.171859    -0.142593     0.136592    -0.004754     0.017493   \n",
       "std       3.801289     1.902182     1.845978     1.005285     1.005351   \n",
       "min     -15.887455    -7.934826    -8.608330    -3.472781    -3.697495   \n",
       "25%      -2.186274    -1.412976    -1.098820    -0.684826    -0.671742   \n",
       "50%       0.087551    -0.117258     0.146639     0.003925     0.028194   \n",
       "75%       2.445656     1.121624     1.411258     0.664399     0.704030   \n",
       "max      17.343261     7.222491     6.664533     3.811616     3.391975   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean     -0.100276     0.000523    -0.051111    -0.010730     0.033355   \n",
       "std       5.071869     1.959944     1.936157     2.068932     2.013369   \n",
       "min     -19.416383    -7.212589    -8.133189    -7.823196    -8.969136   \n",
       "25%      -3.443353    -1.324990    -1.336281    -1.382711    -1.298096   \n",
       "50%       0.076018    -0.037385    -0.066816    -0.036499    -0.033036   \n",
       "75%       3.373809     1.285592     1.244561     1.365567     1.314574   \n",
       "max      19.260556     7.181241     8.819808     7.970802     9.235606   \n",
       "\n",
       "                15           16           17           18           19  \n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  \n",
       "mean     -0.294075    -0.026589    -0.293967     0.000654    -0.356006  \n",
       "std       1.970577     0.978275     1.970967     0.996563     1.794525  \n",
       "min      -7.037129    -3.621038    -7.037129    -4.013615    -7.563245  \n",
       "25%      -1.611778    -0.689233    -1.612217    -0.669329    -1.563380  \n",
       "50%      -0.308584    -0.035249    -0.308293    -0.005563    -0.374563  \n",
       "75%       1.021980     0.635102     1.022347     0.675878     0.824602  \n",
       "max       9.415568     3.951352     9.415568     3.606960     6.774458  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-0.012763</td>\n      <td>-0.261770</td>\n      <td>-0.355985</td>\n      <td>-0.107223</td>\n      <td>-0.505726</td>\n      <td>0.171859</td>\n      <td>-0.142593</td>\n      <td>0.136592</td>\n      <td>-0.004754</td>\n      <td>0.017493</td>\n      <td>-0.100276</td>\n      <td>0.000523</td>\n      <td>-0.051111</td>\n      <td>-0.010730</td>\n      <td>0.033355</td>\n      <td>-0.294075</td>\n      <td>-0.026589</td>\n      <td>-0.293967</td>\n      <td>0.000654</td>\n      <td>-0.356006</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.006266</td>\n      <td>1.852754</td>\n      <td>1.794632</td>\n      <td>3.038180</td>\n      <td>1.818525</td>\n      <td>3.801289</td>\n      <td>1.902182</td>\n      <td>1.845978</td>\n      <td>1.005285</td>\n      <td>1.005351</td>\n      <td>5.071869</td>\n      <td>1.959944</td>\n      <td>1.936157</td>\n      <td>2.068932</td>\n      <td>2.013369</td>\n      <td>1.970577</td>\n      <td>0.978275</td>\n      <td>1.970967</td>\n      <td>0.996563</td>\n      <td>1.794525</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-4.181155</td>\n      <td>-6.980290</td>\n      <td>-7.563245</td>\n      <td>-13.133565</td>\n      <td>-9.011808</td>\n      <td>-15.887455</td>\n      <td>-7.934826</td>\n      <td>-8.608330</td>\n      <td>-3.472781</td>\n      <td>-3.697495</td>\n      <td>-19.416383</td>\n      <td>-7.212589</td>\n      <td>-8.133189</td>\n      <td>-7.823196</td>\n      <td>-8.969136</td>\n      <td>-7.037129</td>\n      <td>-3.621038</td>\n      <td>-7.037129</td>\n      <td>-4.013615</td>\n      <td>-7.563245</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.697289</td>\n      <td>-1.441506</td>\n      <td>-1.563905</td>\n      <td>-1.853387</td>\n      <td>-1.734750</td>\n      <td>-2.186274</td>\n      <td>-1.412976</td>\n      <td>-1.098820</td>\n      <td>-0.684826</td>\n      <td>-0.671742</td>\n      <td>-3.443353</td>\n      <td>-1.324990</td>\n      <td>-1.336281</td>\n      <td>-1.382711</td>\n      <td>-1.298096</td>\n      <td>-1.611778</td>\n      <td>-0.689233</td>\n      <td>-1.612217</td>\n      <td>-0.669329</td>\n      <td>-1.563380</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.028030</td>\n      <td>-0.261043</td>\n      <td>-0.374563</td>\n      <td>-0.021507</td>\n      <td>-0.511772</td>\n      <td>0.087551</td>\n      <td>-0.117258</td>\n      <td>0.146639</td>\n      <td>0.003925</td>\n      <td>0.028194</td>\n      <td>0.076018</td>\n      <td>-0.037385</td>\n      <td>-0.066816</td>\n      <td>-0.036499</td>\n      <td>-0.033036</td>\n      <td>-0.308584</td>\n      <td>-0.035249</td>\n      <td>-0.308293</td>\n      <td>-0.005563</td>\n      <td>-0.374563</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.665953</td>\n      <td>0.944838</td>\n      <td>0.824602</td>\n      <td>1.757076</td>\n      <td>0.688574</td>\n      <td>2.445656</td>\n      <td>1.121624</td>\n      <td>1.411258</td>\n      <td>0.664399</td>\n      <td>0.704030</td>\n      <td>3.373809</td>\n      <td>1.285592</td>\n      <td>1.244561</td>\n      <td>1.365567</td>\n      <td>1.314574</td>\n      <td>1.021980</td>\n      <td>0.635102</td>\n      <td>1.022347</td>\n      <td>0.675878</td>\n      <td>0.824602</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.774161</td>\n      <td>7.155359</td>\n      <td>6.774458</td>\n      <td>10.975842</td>\n      <td>6.420768</td>\n      <td>17.343261</td>\n      <td>7.222491</td>\n      <td>6.664533</td>\n      <td>3.811616</td>\n      <td>3.391975</td>\n      <td>19.260556</td>\n      <td>7.181241</td>\n      <td>8.819808</td>\n      <td>7.970802</td>\n      <td>9.235606</td>\n      <td>9.415568</td>\n      <td>3.951352</td>\n      <td>9.415568</td>\n      <td>3.606960</td>\n      <td>6.774458</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "X_imputer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset senza NaN --> Ora eliminare Outliers Multivariati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nei_cluster, Fuori_Cluster --> Counter({0: 7861, -1: 139})\nNumero di outliersMultivariti trovati --> 139\nIndici degli Outliers:\n [   9   18  112  300  309  403  435  476  490  565  635  643  654  764\n  765  850  870  961  976 1005 1013 1037 1039 1229 1302 1304 1362 1363\n 1472 1517 1574 1586 1589 1592 1707 1776 1824 1841 1880 1935 2003 2035\n 2071 2116 2157 2391 2431 2433 2517 2542 2624 2674 2681 2696 2797 2857\n 2964 3007 3022 3066 3119 3207 3227 3404 3412 3417 3430 3622 3702 3910\n 3955 4005 4031 4111 4135 4147 4182 4242 4368 4383 4400 4485 4582 4650\n 4865 4893 4933 5062 5219 5307 5436 5445 5512 5552 5768 5790 5809 5925\n 5951 5967 6016 6023 6058 6113 6119 6206 6227 6243 6281 6358 6549 6560\n 6577 6665 6678 6714 6754 6808 6872 6879 6950 6975 7093 7105 7166 7184\n 7193 7304 7330 7357 7380 7451 7484 7625 7668 7730 7750 7889 7897]\n"
     ]
    }
   ],
   "source": [
    "Scanner = DBSCAN(eps=6.6, min_samples=10,n_jobs = -1).fit(X_imputer)\n",
    "print('Nei_cluster, Fuori_Cluster -->',Counter(Scanner.labels_))\n",
    "print('Numero di outliersMultivariti trovati -->', Scanner.labels_[Scanner.labels_ == -1] .size)\n",
    "Outliers = X_imputer[Scanner.labels_==-1].index.values\n",
    "print('Indici degli Outliers:\\n', Outliers)\n",
    "x_final = pd.DataFrame(X_imputer).drop(index = Outliers)\n",
    "y_final = y.drop(index = Outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ora Possiamo effettuare Split in Training set e Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTraining set shape: (6288, 20) (6288, 1)\nTest set shape: (1573, 20) (1573, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split in training-set e test-set.\n",
    "train_x, test_x, train_y, test_y = \\\n",
    "        model_select.train_test_split(x_final, y_final,\n",
    "                                      test_size=0.2,\n",
    "                                      random_state=42,\n",
    "                                      stratify=y_final)\n",
    "print('\\nTraining set shape:', train_x.shape, train_y.shape)\n",
    "print('Test set shape:', test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "170000\n8500\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE()\n",
    "train_x, train_y = oversample.fit_resample(train_x, train_y)\n",
    "print(train_x.size)\n",
    "print(train_y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ora eseguiamo le Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo la classe che rimpiazza gli outliers che ci servira per pipeline e perchè KNN non rimpiazza direttamente gli outliers\n",
    "# ma i nan quindi bisogna anche ricreare il metodo fit e il trasform\n",
    "\n",
    "class KNNReplacerIQR(KNNImputer):\n",
    "    \"\"\"Pipeline-compliant KNNReplacer, based on IQR.\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=2):\n",
    "        super().__init__(n_neighbors=n_neighbors)\n",
    "        self.lower_bound = None\n",
    "        self.upper_bound = None\n",
    "        self.imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        \"\"\"Computes IQR bound and fits the imputer on the data.\"\"\"\n",
    "        x = pd.DataFrame(x)\n",
    "        q1 = x.quantile(0.25)\n",
    "        q3 = x.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        self.lower_bound = q1 - (1.5* iqr)\n",
    "        self.upper_bound = q3 + (1.5* iqr)\n",
    "        self.imputer.fit(\n",
    "            x.where(~((x < self.lower_bound) | (x > self.upper_bound)), np.nan)\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        \"\"\"Detects outliers and replaces them with the imputer.\"\"\"\n",
    "        x = pd.DataFrame(x)\n",
    "        x.where(~((x < self.lower_bound) | (x > self.upper_bound)),\n",
    "                np.nan,\n",
    "                inplace=True)\n",
    "        return self.imputer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Principale\n",
    "Pipe_Knn_Bagging = Pipeline([   ('replacer', KNNReplacerIQR()),\n",
    "                                ('pre-process-QDA',PolynomialFeatures(degree=3)),\n",
    "                                ('scaler',StandardScaler()),\n",
    "                                ('decomposition',PCA(random_state = 42)),\n",
    "                                ('feature_selection', SelectFromModel(LinearSVC(C=0.01, penalty=\"l1\", dual=False))),\n",
    "                                ('classifier',BaggingClassifier(\n",
    "                                                 base_estimator=QDA(reg_param = 0.001,store_covariance =True,tol = 0.001),\n",
    "                                                 n_jobs = -1,\n",
    "                                                 random_state = 42))\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_Pipe_Knn_Bagging = {'replacer__n_neighbors': [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_Bagging_knn = model_select.GridSearchCV( Pipe_Knn_Bagging ,\n",
    "                                               param_grid =  grid_Pipe_Knn_Bagging,\n",
    "                                               scoring='f1_macro',\n",
    "                                               cv=5,\n",
    "                                               refit=True,\n",
    "                                               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista pipeline\n",
    "grids = [gs_Bagging_knn]\n",
    "#Dizionario delle pipeline\n",
    "grid_dict_pipe = {0:'BAGGING-KNN'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prova le Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nMODEL OPTIMIZATIONS STARTED\nCurrently trying model: BAGGING-KNN\nGridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('replacer', KNNReplacerIQR()),\n                                       ('pre-process-QDA',\n                                        PolynomialFeatures(degree=3)),\n                                       ('scaler', StandardScaler()),\n                                       ('decomposition', PCA(random_state=42)),\n                                       ('feature_selection',\n                                        SelectFromModel(estimator=LinearSVC(C=0.01,\n                                                                            dual=False,\n                                                                            penalty='l1'))),\n                                       ('classifier',\n                                        BaggingClassifier(base_estimator=QuadraticDiscriminantAnalysis(reg_param=0.001,\n                                                                                                       store_covariance=True,\n                                                                                                       tol=0.001),\n                                                          n_jobs=-1,\n                                                          random_state=42))]),\n             n_jobs=-1, param_grid={'replacer__n_neighbors': [2]},\n             scoring='f1_macro')\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f7b18283ce62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Perform grid search.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mpipe_gs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Dump detailed scores on a file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search objects and look for the best model.\n",
    "print(\"\\nMODEL OPTIMIZATIONS STARTED\")\n",
    "best_f1 = 0.0\n",
    "best_idx = 0\n",
    "best_pipe = None\n",
    "for idx, pipe_gs in enumerate(grids):\n",
    "    print('Currently trying model: %s' % grid_dict_pipe[idx])\n",
    "    print(pipe_gs)\n",
    "\n",
    "    # Perform grid search.\n",
    "    pipe_gs.fit(train_x, train_y[target])\n",
    "\n",
    "    # Dump detailed scores on a file.\n",
    "    results_file = open(grid_dict_pipe[idx] + '_results.txt', 'w')\n",
    "\n",
    "    # Print scores and update bests.\n",
    "    print(\"\\nGrid scores:\")\n",
    "    means = pipe_gs.cv_results_['mean_test_score']\n",
    "    stds = pipe_gs.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds,\n",
    "                                 pipe_gs.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "        results_file.write(\"%0.4f (+/-%0.03f) for %r\\n\"\n",
    "                           % (mean, std * 2, params))\n",
    "    print(\"\\nBest parameters:\")\n",
    "    print(pipe_gs.best_params_)\n",
    "    print(\"\\nBest score: %0.4f\" % pipe_gs.best_score_)\n",
    "    if pipe_gs.best_score_ > best_f1:\n",
    "        best_f1 = pipe_gs.best_score_\n",
    "        best_idx = idx\n",
    "        best_pipe = pipe_gs.best_estimator_\n",
    "    results_file.write(\"\\nBest parameters:\\n%r\\n\" % pipe_gs.best_params_)\n",
    "    results_file.write(\"\\nBest score: %0.4f\\n\" % pipe_gs.best_score_)\n",
    "\n",
    "    results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nPipeline with best training set F1 macro score: BAGGING-KNN\n"
     ]
    }
   ],
   "source": [
    "print('\\nPipeline with best training set F1 macro score: %s'\n",
    "          % grid_dict_pipe[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(cm, f1_score, title):\n",
    "    \"\"\"Displays confusion matrix with annotations.\"\"\"\n",
    "    # Create annotations label.\n",
    "    group_counts = [\"{0:0.0f}\\n\".format(value) for value in cm.flatten()]\n",
    "    group_percentages =\\\n",
    "        [\"{0:.2%}\".format(value) for value in cm.flatten() / np.sum(cm)]\n",
    "    box_labels =\\\n",
    "        [f\"{v1}{v2}\".strip() for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cm.shape[0], cm.shape[1])\n",
    "    # Show confusion matrix with heat map.\n",
    "    sns.heatmap(cm,\n",
    "                annot=box_labels,\n",
    "                fmt=\"\",\n",
    "                cmap=\"YlGnBu\",\n",
    "                cbar=False,\n",
    "                linewidths=1.0)\\\n",
    "        .set(title=title,\n",
    "             xlabel='Predicted class\\n\\nF1 macro: %0.4f' % f1_score,\n",
    "             ylabel='Actual class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(classifier, data_x, data_y, matrix_title='', show=True):\n",
    "    \"\"\"Preprocesses test set and evaluates classifiers.\"\"\"\n",
    "    pred_y = classifier.predict(data_x)\n",
    "    confusion_matrix = metrics.confusion_matrix(data_y, pred_y)\n",
    "    f1_score = metrics.f1_score(data_y, pred_y, average='macro')\n",
    "    if show:\n",
    "        show_confusion_matrix(confusion_matrix, f1_score, matrix_title)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-57e5226ac3e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Evaluates the pipeline on the test set.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m print('\\nTest set F1 macro: %0.4f'\n\u001b[1;32m----> 3\u001b[1;33m           % evaluate_classifier(best_pipe,\n\u001b[0m\u001b[0;32m      4\u001b[0m                                 \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[0mtest_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-0b5a5fa29e42>\u001b[0m in \u001b[0;36mevaluate_classifier\u001b[1;34m(classifier, data_x, data_y, matrix_title, show)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix_title\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Preprocesses test set and evaluates classifiers.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mconfusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mf1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# Evaluates the pipeline on the test set.\n",
    "print('\\nTest set F1 macro: %0.4f'\n",
    "          % evaluate_classifier(best_pipe,\n",
    "                                test_x,\n",
    "                                test_y[target],\n",
    "                                'Test Set Confusion matrix'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RE-FITTING BEST PIPELINE ON WHOLE DATASET\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Pre-save) Dataset F1 macro: 0.9296\n"
     ]
    }
   ],
   "source": [
    "# Refit the best pipeline on the whole dataset.\n",
    "print(\"\\nRE-FITTING BEST PIPELINE ON WHOLE DATASET\")\n",
    "best_pipe = best_pipe.fit(x, y[target])\n",
    "print('\\n(Pre-save) Dataset F1 macro: %0.4f'\n",
    "          % evaluate_classifier(best_pipe,\n",
    "                                x,\n",
    "                                y[target],\n",
    "                                'Dataset Confusion matrix'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize and dump the best model.\n",
    "pipeline_path = 'best_pipeline5.sav'\n",
    "with open(pipeline_path, 'wb') as model_file:\n",
    "        pickle.dump(best_pipe, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Post-save) Dataset F1 macro: 0.9296\n"
     ]
    }
   ],
   "source": [
    "# Reload best model and check if the save went well.\n",
    "with open(pipeline_path, 'rb') as model_file:\n",
    "        model = pickle.load(model_file)\n",
    "print('\\n(Post-save) Dataset F1 macro: %0.4f'\n",
    "          % evaluate_classifier(model,\n",
    "                                x,\n",
    "                                y[target],\n",
    "                                show=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0acd1c3ec51609f20a53a03da2acccc45a09f37cc8f609eca0fec515a53fdbe1a",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}