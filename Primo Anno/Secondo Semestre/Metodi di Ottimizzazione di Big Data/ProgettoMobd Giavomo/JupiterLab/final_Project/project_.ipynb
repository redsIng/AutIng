{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.model_selection as model_select\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection as model_select\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0          NaN  1.357735 -0.645232 -1.524176       NaN -1.524176 -1.220206   \n",
       "1    -0.187455 -0.841512 -0.158584 -3.227462  0.172425 -3.227462  1.411919   \n",
       "2          NaN  1.091768  0.440716 -1.613265  0.055077 -1.613265 -4.278591   \n",
       "3    -1.394021  1.590641  0.246730  4.965631  0.150593  4.965631  1.482024   \n",
       "4     0.606877  0.625310 -0.513682  2.623703       NaN  2.623703  2.335449   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995 -0.192594 -0.453595 -0.057883  0.407408 -1.365127  0.407408 -0.405437   \n",
       "9996 -0.932227 -1.214498  0.942853 -0.906137  0.507329 -0.906137  2.412041   \n",
       "9997  0.246281  1.025481  2.380364 -3.685697 -0.878248 -3.685697  0.924516   \n",
       "9998 -1.252158 -0.974074  0.556018  2.035217       NaN  2.035217 -0.074624   \n",
       "9999 -0.305194  0.965103  0.529415       NaN  0.606347 -0.012325       NaN   \n",
       "\n",
       "            F8        F9       F10  ...       F15       F16       F17  \\\n",
       "0     0.606146       NaN -0.164011  ...  0.932352 -1.934777  0.537243   \n",
       "1          NaN  0.615673 -2.071475  ... -0.415631 -6.031057       NaN   \n",
       "2     1.618829 -0.730272 -3.829564  ... -0.534465       NaN -1.471547   \n",
       "3     2.224675  1.973746  2.656690  ...  0.334828  0.117789 -1.901424   \n",
       "4     0.078711 -0.581077  0.655329  ... -1.217484 -5.670036  0.612314   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995 -1.506944 -0.783212  0.230677  ... -1.075146  4.529417  2.470978   \n",
       "9996  0.757290 -2.169308 -2.320857  ...  0.753918 -2.704671 -1.865146   \n",
       "9997  1.803711  0.567494 -2.029683  ...  0.985395 -4.006701 -5.685372   \n",
       "9998 -4.591799  1.761420 -1.188773  ...  1.039871  7.894771  1.944460   \n",
       "9999  1.408689 -0.257371 -0.955471  ... -0.299682 -4.311096  1.893814   \n",
       "\n",
       "           F18       F19       F20       F21       F22       F23  Label  \n",
       "0     1.053543  5.757696 -0.703544 -2.240894 -0.684588  0.272049    1.0  \n",
       "1     3.321213  2.092218  1.869167  0.473742  1.466099 -0.118461    3.0  \n",
       "2     1.306540  3.886876 -0.195097 -0.456806  1.616122 -0.764173    1.0  \n",
       "3    -1.102605  2.783440 -1.216669 -2.725353 -1.620713 -0.628058    0.0  \n",
       "4    -0.546315  0.063950  1.689753 -0.359699  1.610013  0.054129    1.0  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "9995 -0.309338  3.441702 -2.415452 -1.421139 -0.574091 -0.565556    0.0  \n",
       "9996  0.425525 -6.214690 -2.665123 -0.562713  1.810629 -0.847753    2.0  \n",
       "9997 -1.129747 -2.564002  2.514938 -0.830348  1.686868  1.909690    2.0  \n",
       "9998 -6.047688 -2.121010  1.485629 -0.667930 -0.645083 -1.085183    2.0  \n",
       "9999  2.136538  2.449944  2.473393  1.392571  1.354363 -0.458642    0.0  \n",
       "\n",
       "[10000 rows x 24 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>F1</th>\n      <th>F2</th>\n      <th>F3</th>\n      <th>F4</th>\n      <th>F5</th>\n      <th>F6</th>\n      <th>F7</th>\n      <th>F8</th>\n      <th>F9</th>\n      <th>F10</th>\n      <th>...</th>\n      <th>F15</th>\n      <th>F16</th>\n      <th>F17</th>\n      <th>F18</th>\n      <th>F19</th>\n      <th>F20</th>\n      <th>F21</th>\n      <th>F22</th>\n      <th>F23</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>1.357735</td>\n      <td>-0.645232</td>\n      <td>-1.524176</td>\n      <td>NaN</td>\n      <td>-1.524176</td>\n      <td>-1.220206</td>\n      <td>0.606146</td>\n      <td>NaN</td>\n      <td>-0.164011</td>\n      <td>...</td>\n      <td>0.932352</td>\n      <td>-1.934777</td>\n      <td>0.537243</td>\n      <td>1.053543</td>\n      <td>5.757696</td>\n      <td>-0.703544</td>\n      <td>-2.240894</td>\n      <td>-0.684588</td>\n      <td>0.272049</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.187455</td>\n      <td>-0.841512</td>\n      <td>-0.158584</td>\n      <td>-3.227462</td>\n      <td>0.172425</td>\n      <td>-3.227462</td>\n      <td>1.411919</td>\n      <td>NaN</td>\n      <td>0.615673</td>\n      <td>-2.071475</td>\n      <td>...</td>\n      <td>-0.415631</td>\n      <td>-6.031057</td>\n      <td>NaN</td>\n      <td>3.321213</td>\n      <td>2.092218</td>\n      <td>1.869167</td>\n      <td>0.473742</td>\n      <td>1.466099</td>\n      <td>-0.118461</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>1.091768</td>\n      <td>0.440716</td>\n      <td>-1.613265</td>\n      <td>0.055077</td>\n      <td>-1.613265</td>\n      <td>-4.278591</td>\n      <td>1.618829</td>\n      <td>-0.730272</td>\n      <td>-3.829564</td>\n      <td>...</td>\n      <td>-0.534465</td>\n      <td>NaN</td>\n      <td>-1.471547</td>\n      <td>1.306540</td>\n      <td>3.886876</td>\n      <td>-0.195097</td>\n      <td>-0.456806</td>\n      <td>1.616122</td>\n      <td>-0.764173</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.394021</td>\n      <td>1.590641</td>\n      <td>0.246730</td>\n      <td>4.965631</td>\n      <td>0.150593</td>\n      <td>4.965631</td>\n      <td>1.482024</td>\n      <td>2.224675</td>\n      <td>1.973746</td>\n      <td>2.656690</td>\n      <td>...</td>\n      <td>0.334828</td>\n      <td>0.117789</td>\n      <td>-1.901424</td>\n      <td>-1.102605</td>\n      <td>2.783440</td>\n      <td>-1.216669</td>\n      <td>-2.725353</td>\n      <td>-1.620713</td>\n      <td>-0.628058</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.606877</td>\n      <td>0.625310</td>\n      <td>-0.513682</td>\n      <td>2.623703</td>\n      <td>NaN</td>\n      <td>2.623703</td>\n      <td>2.335449</td>\n      <td>0.078711</td>\n      <td>-0.581077</td>\n      <td>0.655329</td>\n      <td>...</td>\n      <td>-1.217484</td>\n      <td>-5.670036</td>\n      <td>0.612314</td>\n      <td>-0.546315</td>\n      <td>0.063950</td>\n      <td>1.689753</td>\n      <td>-0.359699</td>\n      <td>1.610013</td>\n      <td>0.054129</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>-0.192594</td>\n      <td>-0.453595</td>\n      <td>-0.057883</td>\n      <td>0.407408</td>\n      <td>-1.365127</td>\n      <td>0.407408</td>\n      <td>-0.405437</td>\n      <td>-1.506944</td>\n      <td>-0.783212</td>\n      <td>0.230677</td>\n      <td>...</td>\n      <td>-1.075146</td>\n      <td>4.529417</td>\n      <td>2.470978</td>\n      <td>-0.309338</td>\n      <td>3.441702</td>\n      <td>-2.415452</td>\n      <td>-1.421139</td>\n      <td>-0.574091</td>\n      <td>-0.565556</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>-0.932227</td>\n      <td>-1.214498</td>\n      <td>0.942853</td>\n      <td>-0.906137</td>\n      <td>0.507329</td>\n      <td>-0.906137</td>\n      <td>2.412041</td>\n      <td>0.757290</td>\n      <td>-2.169308</td>\n      <td>-2.320857</td>\n      <td>...</td>\n      <td>0.753918</td>\n      <td>-2.704671</td>\n      <td>-1.865146</td>\n      <td>0.425525</td>\n      <td>-6.214690</td>\n      <td>-2.665123</td>\n      <td>-0.562713</td>\n      <td>1.810629</td>\n      <td>-0.847753</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>0.246281</td>\n      <td>1.025481</td>\n      <td>2.380364</td>\n      <td>-3.685697</td>\n      <td>-0.878248</td>\n      <td>-3.685697</td>\n      <td>0.924516</td>\n      <td>1.803711</td>\n      <td>0.567494</td>\n      <td>-2.029683</td>\n      <td>...</td>\n      <td>0.985395</td>\n      <td>-4.006701</td>\n      <td>-5.685372</td>\n      <td>-1.129747</td>\n      <td>-2.564002</td>\n      <td>2.514938</td>\n      <td>-0.830348</td>\n      <td>1.686868</td>\n      <td>1.909690</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>-1.252158</td>\n      <td>-0.974074</td>\n      <td>0.556018</td>\n      <td>2.035217</td>\n      <td>NaN</td>\n      <td>2.035217</td>\n      <td>-0.074624</td>\n      <td>-4.591799</td>\n      <td>1.761420</td>\n      <td>-1.188773</td>\n      <td>...</td>\n      <td>1.039871</td>\n      <td>7.894771</td>\n      <td>1.944460</td>\n      <td>-6.047688</td>\n      <td>-2.121010</td>\n      <td>1.485629</td>\n      <td>-0.667930</td>\n      <td>-0.645083</td>\n      <td>-1.085183</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>-0.305194</td>\n      <td>0.965103</td>\n      <td>0.529415</td>\n      <td>NaN</td>\n      <td>0.606347</td>\n      <td>-0.012325</td>\n      <td>NaN</td>\n      <td>1.408689</td>\n      <td>-0.257371</td>\n      <td>-0.955471</td>\n      <td>...</td>\n      <td>-0.299682</td>\n      <td>-4.311096</td>\n      <td>1.893814</td>\n      <td>2.136538</td>\n      <td>2.449944</td>\n      <td>2.473393</td>\n      <td>1.392571</td>\n      <td>1.354363</td>\n      <td>-0.458642</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 24 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#Importo dati\n",
    "dataset = pd.read_csv('training_set.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Variabili Indipendenti X:\n             F1        F2        F3        F4        F5        F6        F7  \\\n0          NaN  1.357735 -0.645232 -1.524176       NaN -1.524176 -1.220206   \n1    -0.187455 -0.841512 -0.158584 -3.227462  0.172425 -3.227462  1.411919   \n2          NaN  1.091768  0.440716 -1.613265  0.055077 -1.613265 -4.278591   \n3    -1.394021  1.590641  0.246730  4.965631  0.150593  4.965631  1.482024   \n4     0.606877  0.625310 -0.513682  2.623703       NaN  2.623703  2.335449   \n...        ...       ...       ...       ...       ...       ...       ...   \n9995 -0.192594 -0.453595 -0.057883  0.407408 -1.365127  0.407408 -0.405437   \n9996 -0.932227 -1.214498  0.942853 -0.906137  0.507329 -0.906137  2.412041   \n9997  0.246281  1.025481  2.380364 -3.685697 -0.878248 -3.685697  0.924516   \n9998 -1.252158 -0.974074  0.556018  2.035217       NaN  2.035217 -0.074624   \n9999 -0.305194  0.965103  0.529415       NaN  0.606347 -0.012325       NaN   \n\n            F8        F9       F10  ...       F14       F15       F16  \\\n0     0.606146       NaN -0.164011  ...  1.159030  0.932352 -1.934777   \n1          NaN  0.615673 -2.071475  ...  2.377373 -0.415631 -6.031057   \n2     1.618829 -0.730272 -3.829564  ...  3.795801 -0.534465       NaN   \n3     2.224675  1.973746  2.656690  ...  0.817206  0.334828  0.117789   \n4     0.078711 -0.581077  0.655329  ...  3.959806 -1.217484 -5.670036   \n...        ...       ...       ...  ...       ...       ...       ...   \n9995 -1.506944 -0.783212  0.230677  ... -0.399634 -1.075146  4.529417   \n9996  0.757290 -2.169308 -2.320857  ... -0.424400  0.753918 -2.704671   \n9997  1.803711  0.567494 -2.029683  ... -2.257330  0.985395 -4.006701   \n9998 -4.591799  1.761420 -1.188773  ...  0.278827  1.039871  7.894771   \n9999  1.408689 -0.257371 -0.955471  ...  2.552580 -0.299682 -4.311096   \n\n           F17       F18       F19       F20       F21       F22       F23  \n0     0.537243  1.053543  5.757696 -0.703544 -2.240894 -0.684588  0.272049  \n1          NaN  3.321213  2.092218  1.869167  0.473742  1.466099 -0.118461  \n2    -1.471547  1.306540  3.886876 -0.195097 -0.456806  1.616122 -0.764173  \n3    -1.901424 -1.102605  2.783440 -1.216669 -2.725353 -1.620713 -0.628058  \n4     0.612314 -0.546315  0.063950  1.689753 -0.359699  1.610013  0.054129  \n...        ...       ...       ...       ...       ...       ...       ...  \n9995  2.470978 -0.309338  3.441702 -2.415452 -1.421139 -0.574091 -0.565556  \n9996 -1.865146  0.425525 -6.214690 -2.665123 -0.562713  1.810629 -0.847753  \n9997 -5.685372 -1.129747 -2.564002  2.514938 -0.830348  1.686868  1.909690  \n9998  1.944460 -6.047688 -2.121010  1.485629 -0.667930 -0.645083 -1.085183  \n9999  1.893814  2.136538  2.449944  2.473393  1.392571  1.354363 -0.458642  \n\n[10000 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Separiamo le classi dalle features\n",
    "target = 'Label'\n",
    "x = dataset.drop(target, axis=1)\n",
    "print('Variabili Indipendenti X:\\n', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nVariabili Dipendenti Y:\n       Label\n0       1.0\n1       3.0\n2       1.0\n3       0.0\n4       1.0\n...     ...\n9995    0.0\n9996    2.0\n9997    2.0\n9998    2.0\n9999    0.0\n\n[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Classi\n",
    "y = dataset[[target]]\n",
    "print('\\nVariabili Dipendenti Y:\\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lista Features:\n ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21', 'F22', 'F23']\n"
     ]
    }
   ],
   "source": [
    "# Lista delle features\n",
    "features_list = x.columns.values.tolist()\n",
    "print('Lista Features:\\n', features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTraining set shape: (8000, 23) (8000, 1)\nTest set shape: (2000, 23) (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split in training-set e test-set.\n",
    "train_x, test_x, train_y, test_y = \\\n",
    "        model_select.train_test_split(x, y,\n",
    "                                      test_size=0.2,\n",
    "                                      random_state=42,\n",
    "                                      stratify=y)\n",
    "print('\\nTraining set shape:', train_x.shape, train_y.shape)\n",
    "print('Test set shape:', test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo la classe che rimpiazza gli outliers che ci servira per pipeline e perchè KNN non rimpiazza direttamente gli outliers\n",
    "# ma i nan quindi bisogna anche ricreare il metodo fit e il trasform\n",
    "\n",
    "class KNNReplacerIQR(KNNImputer):\n",
    "    \"\"\"Pipeline-compliant KNNReplacer, based on IQR.\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        super().__init__(n_neighbors=n_neighbors)\n",
    "        self.lower_bound = None\n",
    "        self.upper_bound = None\n",
    "        self.imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        \"\"\"Computes IQR bound and fits the imputer on the data.\"\"\"\n",
    "        x = pd.DataFrame(x)\n",
    "        q1 = x.quantile(0.25)\n",
    "        q3 = x.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        self.lower_bound = q1 - (3* iqr)\n",
    "        self.upper_bound = q3 + (3* iqr)\n",
    "        self.imputer.fit(\n",
    "            x.where(~((x < self.lower_bound) | (x > self.upper_bound)), np.nan)\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, x, y=None):\n",
    "        \"\"\"Detects outliers and replaces them with the imputer.\"\"\"\n",
    "        x = pd.DataFrame(x)\n",
    "        x.where(~((x < self.lower_bound) | (x > self.upper_bound)),\n",
    "                np.nan,\n",
    "                inplace=True)\n",
    "        return self.imputer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "   class DBScanner(DBSCAN):\n",
    "        outliers = []\n",
    "        def __init__(self,eps=10,min_samples=100):\n",
    "            super().__init__(eps=eps,min_samples=min_samples)\n",
    "            #self.Scanner = DBSCAN(eps=eps,min_samples=min_samples)\n",
    "            \n",
    "        def fit(self,x,y=None):\n",
    "            x = pd.DataFrame(x)\n",
    "            model = super().fit(x)\n",
    "            outliers = x[model.labels_==-1].index.values\n",
    "        \n",
    "        def transform(self, x, y=None):\n",
    "            x = pd.DataFrame(x).drop(index = outliers)\n",
    "            return self.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mia PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_pipeline():\n",
    "    \n",
    "    # Definisco la mia Pipeline e lista di azioni da eseguire\n",
    "    Pipe_Knn_Dbscan_Knn_QDA = Pipeline([('imputer' , KNNImputer()),\n",
    "                                        ('cluster' , DBScanner()),\n",
    "                                        ('replacer' , KNNReplacerIQR()),\n",
    "                                        ('scaler' , RobustScaler()),\n",
    "                                        ('classifier' , QuadraticDiscriminantAnalysis())\n",
    "                                        ])\n",
    "    \n",
    "    Pipe_Knn_QDA = Pipeline([('imputer' , KNNImputer()),\n",
    "                            ('replacer' , KNNReplacerIQR()),\n",
    "                            ('scaler' , RobustScaler()),\n",
    "                            ('classifier' , QuadraticDiscriminantAnalysis())\n",
    "                            ])\n",
    "    \n",
    "    Pipe_Knn_Dbscan_Knn_Bagging = Pipeline([('imputer' , KNNImputer()),\n",
    "                                        ('cluster' , DBScanner()),\n",
    "                                        ('replacer' , KNNReplacerIQR()),\n",
    "                                        ('scaler' , RobustScaler()),\n",
    "                                        ('classifier' , BaggingClassifier(\n",
    "                                                        base_estimator=QuadraticDiscriminantAnalysis(),\n",
    "                                                        random_state = 42))\n",
    "                                        ])\n",
    "    \n",
    "    Pipe_Knn_Bagging = Pipeline([('imputer' , KNNImputer()),\n",
    "                                ('replacer' , KNNReplacerIQR()),\n",
    "                                ('scaler' , RobustScaler()),\n",
    "                                ('classifier' ,  BaggingClassifier(\n",
    "                                                 base_estimator=QuadraticDiscriminantAnalysis(),\n",
    "                                                 random_state = 42))\n",
    "                                ])\n",
    "    \n",
    "    #Setto i parametri che dovrà usare Pipeline ad ogni iterazione\n",
    "    grid_Pipe_Knn_Dbscan_Knn_QDA = {'imputer__n_neighbors' : [2, 5, 10],\n",
    "                                    'cluster__eps' : [10, 15,20], #[0.1 , 0.5 , 1],\n",
    "                                    'cluster__min_samples' : [500, 1000, 1500], #[5, 10, [100, 200, 1000],\n",
    "                                    'replacer__n_neighbors' : [2, 5, 10]\n",
    "                                    }\n",
    "    \n",
    "    grid_Pipe_Knn_QDA = {'imputer__n_neighbors' : [2, 5, 10] ,\n",
    "                         'replacer__n_neighbors' : [2, 5, 10]\n",
    "                        }\n",
    "    \n",
    "    grid_Pipe_Knn_Dbscan_Knn_Bagging = {'imputer__n_neighbors' : [2, 5, 10],\n",
    "                                         'cluster__eps' : [0.1 , 0.5 , 1],#,5, 10, 15],\n",
    "                                         'cluster__min_samples' : [500, 1000, 1500],#[5, 10, 100]\n",
    "                                         'replacer__n_neighbors' : [2, 5, 10]\n",
    "                                        }\n",
    "    grid_Pipe_Knn_Bagging = {'imputer__n_neighbors' : [2, 5, 10] ,\n",
    "                             'replacer__n_neighbors' : [2, 5, 10]\n",
    "                            }\n",
    "    \n",
    "    #Definisco le grid search per le pipeline\n",
    "    gs_QDA_knn_Dbscan = model_select.GridSearchCV( Pipe_Knn_Dbscan_Knn_QDA,\n",
    "                                               param_grid =  grid_Pipe_Knn_Dbscan_Knn_QDA,\n",
    "                                               scoring='f1_macro',\n",
    "                                               cv=5,\n",
    "                                               refit=True,\n",
    "                                               n_jobs=-1) \n",
    "    \n",
    "    \n",
    "    gs_QDA_knn= model_select.GridSearchCV( Pipe_Knn_QDA,\n",
    "                                               param_grid = grid_Pipe_Knn_QDA ,\n",
    "                                               scoring='f1_macro',\n",
    "                                               cv=5,\n",
    "                                               refit=True,\n",
    "                                               n_jobs=-1) \n",
    "    \n",
    "    gs_Bagging_knn_Dbscan = model_select.GridSearchCV( Pipe_Knn_Dbscan_Knn_Bagging,\n",
    "                                               param_grid =  grid_Pipe_Knn_Dbscan_Knn_Bagging,\n",
    "                                               scoring='f1_macro',\n",
    "                                               cv=5,\n",
    "                                               refit=True,\n",
    "                                               n_jobs=-1) \n",
    "    \n",
    "    gs_Bagging_knn = model_select.GridSearchCV( Pipe_Knn_Bagging ,\n",
    "                                               param_grid =  grid_Pipe_Knn_Bagging,\n",
    "                                               scoring='f1_macro',\n",
    "                                               cv=5,\n",
    "                                               refit=True,\n",
    "                                               n_jobs=-1) \n",
    "    \n",
    "    # Lista pipeline\n",
    "    grids = [gs_QDA_knn_Dbscan,\n",
    "             gs_QDA_knn,\n",
    "             gs_Bagging_knn_Dbscan,\n",
    "             gs_Bagging_knn]\n",
    "    \n",
    "    #Dizionario delle pipeline\n",
    "    grid_dict_pipe = {0: 'QDA-KNN-DBSCAN',\n",
    "                  1: 'QDA-KNN',\n",
    "                  2: 'BAGGING-KNN-DBSCAN',\n",
    "                  3: 'BAGGING-KNN'}\n",
    "    \n",
    "    return grids, grid_dict_pipe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Definisco la mia Pipeline e lista di azioni da eseguire\n",
    "Pipe_Knn_Bagging = Pipeline([('imputer' , KNNImputer()),\n",
    "                                ('replacer' , KNNReplacerIQR()),\n",
    "                                ('scaler' , RobustScaler()),\n",
    "                                ('classifier' ,GaussianProcessClassifier(1.0 * RBF(1.0)) )\n",
    "                                ])\n",
    "#BaggingClassifier(\n",
    "        #                base_estimator=SVC(),\n",
    "                                              #   random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Setto i parametri che dovrà usare Pipeline ad ogni iterazione\n",
    "grid_Pipe_Knn_Bagging = {'imputer__n_neighbors' : [2, 5, 10] ,\n",
    "                         'replacer__n_neighbors' : [2, 5, 10],\n",
    "                         \n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definisco le grid search per le pipeline\n",
    "gs_Bagging_knn = model_select.GridSearchCV( Pipe_Knn_Bagging ,\n",
    "                                               param_grid =  grid_Pipe_Knn_Bagging,\n",
    "                                               scoring='f1_macro',\n",
    "                                               cv=5,\n",
    "                                               refit=True,\n",
    "                                               n_jobs=-1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pipeline grids for ease of iteration.\n",
    "grids = [gs_Bagging_knn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pipelines and classifier types for ease of reference.\n",
    "grid_dict_pipe = {0: 'GaussianProcessClassifier'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grids, grid_dict_pipe = get_my_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL OPTIMIZATIONS STARTED\n",
      "Currently trying model: GaussianProcessClassifier\n",
      "GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('imputer', KNNImputer()),\n",
      "                                       ('replacer', KNNReplacerIQR()),\n",
      "                                       ('scaler', RobustScaler()),\n",
      "                                       ('classifier',\n",
      "                                        GaussianProcessClassifier(kernel=1**2 * RBF(length_scale=1)))]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'imputer__n_neighbors': [2, 5, 10],\n",
      "                         'replacer__n_neighbors': [2, 5, 10]},\n",
      "             scoring='f1_macro')\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search objects and look for the best model.\n",
    "print(\"\\nMODEL OPTIMIZATIONS STARTED\")\n",
    "best_f1 = 0.0\n",
    "best_idx = 0\n",
    "best_pipe = None\n",
    "for idx, pipe_gs in enumerate(grids):\n",
    "    print('Currently trying model: %s' % grid_dict_pipe[idx])\n",
    "    print(pipe_gs)\n",
    "\n",
    "    # Perform grid search.\n",
    "    pipe_gs.fit(train_x, train_y[target])\n",
    "\n",
    "    # Dump detailed scores on a file.\n",
    "    results_file = open(grid_dict_pipe[idx] + '_results.txt', 'w')\n",
    "\n",
    "    # Print scores and update bests.\n",
    "    print(\"\\nGrid scores:\")\n",
    "    means = pipe_gs.cv_results_['mean_test_score']\n",
    "    stds = pipe_gs.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds,\n",
    "                                 pipe_gs.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "        results_file.write(\"%0.4f (+/-%0.03f) for %r\\n\"\n",
    "                           % (mean, std * 2, params))\n",
    "    print(\"\\nBest parameters:\")\n",
    "    print(pipe_gs.best_params_)\n",
    "    print(\"\\nBest score: %0.4f\" % pipe_gs.best_score_)\n",
    "    if pipe_gs.best_score_ > best_f1:\n",
    "        best_f1 = pipe_gs.best_score_\n",
    "        best_idx = idx\n",
    "        best_pipe = pipe_gs.best_estimator_\n",
    "    results_file.write(\"\\nBest parameters:\\n%r\\n\" % pipe_gs.best_params_)\n",
    "    results_file.write(\"\\nBest score: %0.4f\\n\" % pipe_gs.best_score_)\n",
    "\n",
    "    results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "acd1c3ec51609f20a53a03da2acccc45a09f37cc8f609eca0fec515a53fdbe1a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}