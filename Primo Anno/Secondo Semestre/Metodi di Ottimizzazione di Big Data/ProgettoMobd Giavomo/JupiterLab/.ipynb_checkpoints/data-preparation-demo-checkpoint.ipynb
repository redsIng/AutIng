{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 1.14.0\n",
      "numpy: 1.16.4\n",
      "pandas: 0.25.1\n",
      "matplotlib: 3.1.1\n",
      "scikit-learn: 0.21.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.preprocessing as prep\n",
    "print(\"tensorflow:\", tf.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"matplotlib:\", matplotlib.__version__)\n",
    "print('scikit-learn:', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrizione del dataset\n",
    "Questo notebook utilizza il classico set di dati 'Auto MPG' e costruisce un modello per prevedere l'efficienza del consumo di carburante dalla fine degli anni '70 all'inizio degli anni '80. Per fare questo, forniremo al modello una descrizione di molte automobili di quel periodo di tempo. La descrizione forinita include attributi come: numero di cilindri, cilindrata, potenza e peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (398, 8)\n",
      "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
      "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
      "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
      "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
      "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
      "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
      "\n",
      "     Model Year  Origin  \n",
      "393          82       1  \n",
      "394          82       2  \n",
      "395          82       1  \n",
      "396          82       1  \n",
      "397          82       1  \n"
     ]
    }
   ],
   "source": [
    "dataset_path = './auto-mpg.data'\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "# leggiamo i dati specificando le colonne opportune\n",
    "dataset = pd.read_csv(dataset_path, names=column_names, na_values = \"?\", comment='\\t', sep=\" \", skipinitialspace=True)\n",
    "print('Shape:', dataset.shape)\n",
    "print(dataset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset shape: (318, 7) train_labels shape: (318,)\n",
      "test_dataset shape: (80, 7) test_labels shape: (80,)\n"
     ]
    }
   ],
   "source": [
    "# Ora dividiamo il dataset in training set e test set secondo le proporzioni 80-20\n",
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "\n",
    "# separiamo le caratteristiche dalla variabile continua che vogliamo prevedere 'MPG'\n",
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')\n",
    "\n",
    "print(\"train_dataset shape:\", train_dataset.shape, \"train_labels shape:\", train_labels.shape)\n",
    "print(\"test_dataset shape:\", test_dataset.shape, \"test_labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizziamo il dataset e individuiamo eventuali valori mancanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione che conta il numero di valori mancanti per ogni attributo\n",
    "def get_na_count(dataset):\n",
    "    # per ogni elemento (i,j) del dataset, isna() restituisce \n",
    "    # TRUE/FALSE se il valore corrispondente è mancante/presente\n",
    "    boolean_mask = dataset.isna()\n",
    "    # contiamo il numero di TRUE per ogni attributo sul dataset\n",
    "    return boolean_mask.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cylinders       0\n",
      "Displacement    0\n",
      "Horsepower      5\n",
      "Weight          0\n",
      "Acceleration    0\n",
      "Model Year      0\n",
      "Origin          0\n",
      "dtype: int64\n",
      "Cylinders       0\n",
      "Displacement    0\n",
      "Horsepower      1\n",
      "Weight          0\n",
      "Acceleration    0\n",
      "Model Year      0\n",
      "Origin          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# calcoliamo il numero di valori mancanti su train e test\n",
    "summary_train = get_na_count(train_dataset)\n",
    "print(summary_train)\n",
    "summary_test = get_na_count(test_dataset)\n",
    "print(summary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sostituiamo i valori mancanti per la feature 'Hosepower' con la media calcolata sul training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Horsepower: 104.06709265175719\n",
      "Cylinders       0\n",
      "Displacement    0\n",
      "Horsepower      0\n",
      "Weight          0\n",
      "Acceleration    0\n",
      "Model Year      0\n",
      "Origin          0\n",
      "dtype: int64\n",
      "Cylinders       0\n",
      "Displacement    0\n",
      "Horsepower      0\n",
      "Weight          0\n",
      "Acceleration    0\n",
      "Model Year      0\n",
      "Origin          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# calcoliamo la media della colonna che ci interessa\n",
    "horsepower_mean_train = train_dataset['Horsepower'].mean()\n",
    "print('Mean Horsepower:', horsepower_mean_train)\n",
    "\n",
    "# sostituiamo i valori mancanti con la media\n",
    "train_dataset['Horsepower'] = train_dataset['Horsepower'].fillna(horsepower_mean_train)\n",
    "test_dataset['Horsepower'] = test_dataset['Horsepower'].fillna(horsepower_mean_train)\n",
    "\n",
    "# controlliamo nuovamente train e test\n",
    "summary_train = get_na_count(train_dataset)\n",
    "print(summary_train)\n",
    "summary_test = get_na_count(test_dataset)\n",
    "print(summary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osserviamo che 'Origin' è una variabile categorica non ordinale che assume tre possibili valori 1 (USA), 2 (Europe), 3 (Japan). Dobbiamo convertirla in 3 variabili numeriche tramite la codifica one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     USA  Europe  Japan\n",
      "207    0       1      0\n",
      "279    0       0      1\n",
      "227    1       0      0\n",
      "148    0       1      0\n",
      "143    0       1      0\n",
      "     USA  Europe  Japan\n",
      "368    1       0      0\n",
      "370    1       0      0\n",
      "382    0       0      1\n",
      "384    0       0      1\n",
      "396    1       0      0\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding della feature 'Origin' per train e test\n",
    "classes = ['USA', 'Europe', 'Japan']\n",
    "binarizer = prep.LabelBinarizer()\n",
    "binarizer.fit(train_dataset['Origin'])\n",
    "train_one_hot = binarizer.transform(train_dataset['Origin'])\n",
    "train_one_hot = pd.DataFrame(train_one_hot, columns=classes, index=train_dataset.index)\n",
    "print(train_one_hot.tail())\n",
    "test_one_hot = binarizer.transform(test_dataset['Origin'])\n",
    "test_one_hot = pd.DataFrame(test_one_hot, columns=classes, index=test_dataset.index)\n",
    "print(test_one_hot.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year  \\\n",
      "207          4         130.0       102.0  3150.0          15.7          76   \n",
      "279          4          98.0        68.0  2135.0          16.6          78   \n",
      "227          6         225.0       100.0  3630.0          17.7          77   \n",
      "148          4         116.0        75.0  2246.0          14.0          74   \n",
      "143          4          97.0        78.0  2300.0          14.5          74   \n",
      "\n",
      "     USA  Europe  Japan  \n",
      "207    0       1      0  \n",
      "279    0       0      1  \n",
      "227    1       0      0  \n",
      "148    0       1      0  \n",
      "143    0       1      0  \n",
      "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year  \\\n",
      "368          4         112.0        88.0  2640.0          18.6          82   \n",
      "370          4         112.0        85.0  2575.0          16.2          82   \n",
      "382          4         108.0        70.0  2245.0          16.9          82   \n",
      "384          4          91.0        67.0  1965.0          15.7          82   \n",
      "396          4         120.0        79.0  2625.0          18.6          82   \n",
      "\n",
      "     USA  Europe  Japan  \n",
      "368    1       0      0  \n",
      "370    1       0      0  \n",
      "382    0       0      1  \n",
      "384    0       0      1  \n",
      "396    1       0      0  \n"
     ]
    }
   ],
   "source": [
    "# eliminiamo la colonna categorica\n",
    "train_dataset = train_dataset.drop(['Origin'], axis=1)\n",
    "test_dataset = test_dataset.drop(['Origin'], axis=1)\n",
    "\n",
    "# aggiungiamo le feature binarie\n",
    "train_dataset = pd.concat([train_dataset, train_one_hot], axis=1)\n",
    "test_dataset = pd.concat([test_dataset, test_one_hot], axis=1)\n",
    "\n",
    "print(train_dataset.tail())\n",
    "print(test_dataset.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318, 9) (318, 1)\n",
      "(80, 9) (80, 1)\n"
     ]
    }
   ],
   "source": [
    "# convertiamo i DataFrame per l'input e per l'output in vettori 2D (matrici)\n",
    "train_x = np.float64(train_dataset.values)\n",
    "train_y = np.float64(train_labels.values)\n",
    "train_y = train_y.reshape((len(train_y), 1))\n",
    "test_x = np.float64(test_dataset.values)\n",
    "test_y = np.float64(test_labels.values)\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È buona norma normalizzare le feature che utilizzano scale e intervalli diversi. Non normalizzare i dati rende l'allenamento più difficile e rende il modello risultante dipendente dalla scelta delle unità nell'input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizziamo il MinMaxScaler che applica la seguente trasformazione:\n",
    "# X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "# X_scaled = X_std * (max - min) + min\n",
    "\n",
    "scaler_x = prep.MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = prep.MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_x.fit(train_x)\n",
    "scaler_y.fit(train_y)\n",
    "scaled_train_x = scaler_x.transform(train_x)\n",
    "scaled_train_y = scaler_y.transform(train_y)\n",
    "scaled_test_x = scaler_x.transform(test_x)\n",
    "scaled_test_y = scaler_y.transform(test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
